{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb0b226e",
   "metadata": {},
   "source": [
    "## scRNA-seq (10x) preprocessing with Scanpy (+ optional HashSolo)\n",
    "Generic pipeline to prepare 10x GEX data for QC and filtering, with optional HTO demultiplexing.\n",
    "\n",
    "### References\n",
    "- [Scanpy: clustering basics](https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html)\n",
    "- [scVI-tools docs](https://docs.scvi-tools.org/en/stable/)\n",
    "- [Scanpy docs](https://scanpy.readthedocs.io/en/stable/)\n",
    "- [HashSolo paper](https://www.cell.com/cell-systems/fulltext/S2405-4712(20)30195-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09226af",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b02dde11",
   "metadata": {},
   "source": [
    "### Configuration Parameters\n",
    "Define library-specific parameters before running the pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abee8d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== CONFIGURATION ====================\n",
    "# Modify these parameters for your specific library\n",
    "\n",
    "# Library identification\n",
    "LIBRARY_NAME = \"PBS-CFA\"  # Name of your library\n",
    "BATCH_NAME = \"Mistri\"    # Batch identifier for future merging\n",
    "SEX = \"female\"            # Sex of the library (e.g., \"male\", \"female\", \"unknown\")\n",
    "\n",
    "# Output prefix (will be added to all plot and output file names)\n",
    "OUTPUT_PREFIX = \"PBS-CFA\"\n",
    "\n",
    "# HashSolo demultiplexing options\n",
    "USE_HASHSOLO = True  # Set to True if you have HTO data and want to demultiplex\n",
    "                      # Set to False for GEX-only analysis\n",
    "\n",
    "# Data paths (relative to the 'inputs' directory)\n",
    "INPUT_DATA_PATH = \"filtered_feature_bc_matrix\"  # Path to 10x data folder within inputs/\n",
    "\n",
    "# ========================================================\n",
    "\n",
    "print(f\"Configuration loaded:\")\n",
    "print(f\"  Library: {LIBRARY_NAME}\")\n",
    "print(f\"  Batch: {BATCH_NAME}\")\n",
    "print(f\"  Sex: {SEX}\")\n",
    "print(f\"  Output prefix: {OUTPUT_PREFIX}\")\n",
    "print(f\"  Use HashSolo: {USE_HASHSOLO}\")\n",
    "print(f\"  Input data: inputs/{INPUT_DATA_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3d4144",
   "metadata": {},
   "source": [
    "### Pipeline Overview\n",
    "- Configure library parameters (batch, sex, output prefix, hashsolo option)\n",
    "- Import packages\n",
    "- Load 10x data (GEX + optional HTO)\n",
    "- Build `AnnData` with GEX; attach HTO to obsm (if available)\n",
    "- Run HashSolo demultiplexing (if enabled)\n",
    "- Add mouse column\n",
    "- Perform QC filtering\n",
    "- Save QC-filtered data\n",
    "- Perform clustering and visualization (for contamination detection)\n",
    "- Save final clustered data with raw counts preserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6e03dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import scanpy as sc\n",
    "import scvi\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "import anndata as ad\n",
    "import re\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import scanpy.external as sce\n",
    "import sys, pkg_resources, datetime\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "\n",
    "# Paths and plotting\n",
    "data_dir = Path('inputs')\n",
    "results_dir = Path('outputs')\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "png_dir = results_dir / \"png\"\n",
    "pdf_dir = results_dir / \"pdf\"\n",
    "png_dir.mkdir(parents=True, exist_ok=True)\n",
    "pdf_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Plot defaults\n",
    "sc.set_figure_params(dpi=300, figsize=(6, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea4fce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 10x data\n",
    "print(f\"Loading data from: {INPUT_DATA_PATH}\")\n",
    "\n",
    "# Load 10x dataset (including HTOs if present)\n",
    "adata_full = sc.read_10x_mtx(\n",
    "    data_dir / INPUT_DATA_PATH,\n",
    "    var_names='gene_symbols',\n",
    "    cache=False,\n",
    "    gex_only=False\n",
    ")\n",
    "\n",
    "# Add metadata\n",
    "adata_full.obs['library'] = LIBRARY_NAME\n",
    "adata_full.obs['batch'] = BATCH_NAME\n",
    "adata_full.obs['sex'] = SEX\n",
    "adata_full.obs_names_make_unique()\n",
    "\n",
    "# Inspect feature types\n",
    "print(f\"\\nFeature types found:\")\n",
    "print(adata_full.var['feature_types'].value_counts())\n",
    "\n",
    "# Extract RNA/GEX only\n",
    "adata = adata_full[:, adata_full.var['feature_types'] == 'Gene Expression'].copy()\n",
    "print(f\"\\nGEX data shape: {adata.shape}\")\n",
    "\n",
    "# Check for HTO/Antibody Capture data\n",
    "has_hto = 'Antibody Capture' in adata_full.var['feature_types'].values\n",
    "\n",
    "if has_hto:\n",
    "    hto_subset = adata_full[:, adata_full.var['feature_types'] == 'Antibody Capture']\n",
    "    adata.obsm['HTO'] = hto_subset.X.toarray() if hasattr(hto_subset.X, \"toarray\") else hto_subset.X\n",
    "    adata.uns['HTO_features'] = hto_subset.var_names.to_list()\n",
    "    print(f\"HTO data shape: {adata.obsm['HTO'].shape}\")\n",
    "    print(f\"HTO features: {adata.uns['HTO_features']}\")\n",
    "else:\n",
    "    print(\"No HTO/Antibody Capture data found\")\n",
    "    if USE_HASHSOLO:\n",
    "        print(\"WARNING: USE_HASHSOLO is True but no HTO data available. HashSolo will be skipped.\")\n",
    "\n",
    "print(f\"\\nâœ… Data loaded successfully with {adata.n_obs} cells and {adata.n_vars} genes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424c270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick data inspection\n",
    "print(f\"\\n=== Data Inspection ===\")\n",
    "\n",
    "# Inspect raw RNA counts\n",
    "print(f\"\\nadata.X type: {type(adata.X)}\")\n",
    "print(f\"adata.X shape: {adata.X.shape}\")\n",
    "\n",
    "# Inspect HTO data (if present)\n",
    "if 'HTO' in adata.obsm:\n",
    "    print(f\"\\nHTO shape: {adata.obsm['HTO'].shape}\")\n",
    "    print(f\"HTO features: {adata.uns.get('HTO_features', 'Not available')}\")\n",
    "else:\n",
    "    print(\"\\nNo HTO data in adata.obsm\")\n",
    "\n",
    "# Inspect metadata\n",
    "print(f\"\\nadata.obs shape: {adata.obs.shape}\")\n",
    "print(\"Metadata columns (first 5 rows):\")\n",
    "print(adata.obs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e61714",
   "metadata": {},
   "source": [
    "### Demultiplex HTO with HashSolo (Optional)\n",
    "Run HashSolo demultiplexing if USE_HASHSOLO is True and HTO data is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef9f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run HashSolo if enabled and HTO data is available\n",
    "if USE_HASHSOLO and has_hto:\n",
    "    print(f\"\\n=== Running HashSolo Demultiplexing ===\")\n",
    "    \n",
    "    # Get HTO counts and features\n",
    "    hto_counts = adata.obsm['HTO']\n",
    "    hto_features = adata.uns['HTO_features']\n",
    "    \n",
    "    # Create DataFrame\n",
    "    hto_df = pd.DataFrame(\n",
    "        hto_counts.toarray() if hasattr(hto_counts, 'toarray') else hto_counts,\n",
    "        index=adata.obs_names,\n",
    "        columns=hto_features\n",
    "    )\n",
    "    \n",
    "    # Add HTO columns to obs\n",
    "    for col in hto_df.columns:\n",
    "        adata.obs[f\"HTO_{col}\"] = hto_df.loc[adata.obs_names, col].values\n",
    "    \n",
    "    hto_columns = [f\"HTO_{col}\" for col in hto_features]\n",
    "    \n",
    "    # Run HashSolo\n",
    "    print(f\"Running HashSolo...\")\n",
    "    sce.pp.hashsolo(adata, cell_hashing_columns=hto_columns, inplace=True)\n",
    "    \n",
    "    # Summarize assignments\n",
    "    print(f\"\\nClassification:\")\n",
    "    print(adata.obs['Classification'].value_counts())\n",
    "    print(f\"\\nmost_likely_hypothesis:\")\n",
    "    print(adata.obs['most_likely_hypothesis'].value_counts())\n",
    "    \n",
    "    print(\"\\nâœ… HashSolo demultiplexing completed\")\n",
    "else:\n",
    "    if not USE_HASHSOLO:\n",
    "        print(\"\\nâ­ï¸  HashSolo skipped (USE_HASHSOLO is False)\")\n",
    "    elif not has_hto:\n",
    "        print(\"\\nâ­ï¸  HashSolo skipped (No HTO data available)\")\n",
    "    \n",
    "    # Add placeholder columns for consistency\n",
    "    adata.obs['Classification'] = 'Not_demultiplexed'\n",
    "    adata.obs['most_likely_hypothesis'] = 'N/A'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b55818a",
   "metadata": {},
   "source": [
    "### Add Mouse Column\n",
    "Create a mouse identifier column by copying the library name. This allows tracking of individual mice, especially useful when merging multiple libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eb4cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add mouse column\n",
    "adata.obs['mouse'] = adata.obs['Classification'].copy()\n",
    "\n",
    "print(f\"\\nâœ… Added 'mouse' column\")\n",
    "print(f\"Unique mouse IDs:\")\n",
    "print(adata.obs['mouse'].unique())\n",
    "print(f\"\\nMouse ID counts:\")\n",
    "print(adata.obs['mouse'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faad1fc",
   "metadata": {},
   "source": [
    "### Cell Cycle Scoring (Mouse Gene Lists)\n",
    "Compute cell cycle scores using mouse gene lists on normalized copies of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9f1336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell Cycle Scoring\n",
    "# Mouse gene lists for cell cycle scoring\n",
    "s_genes = [\n",
    "    'Mcm5', 'Pcna', 'Tyms', 'Fen1', 'Mcm2', 'Mcm4', 'Rrm1', 'Ung', 'Gins2', 'Mcm6',\n",
    "    'Cdca7', 'Dtl', 'Prim1', 'Uhrf1', 'Hells', 'Rfc2', 'Rpa2', 'Nasp', 'Rad51ap1',\n",
    "    'Gmnn', 'Wdr76', 'Slbp', 'Ccne2', 'Ubr7', 'Pold3', 'Msh2', 'Atad2', 'Rad51',\n",
    "    'Rrm2', 'Cdc45', 'Cdc6', 'Exo1', 'Tipin', 'Dscc1', 'Blm', 'Casp8ap2', 'Usp1',\n",
    "    'Clspn', 'Pola1', 'Chaf1b', 'Brip1', 'E2f8'\n",
    "]\n",
    "\n",
    "g2m_genes = [\n",
    "    'Hmgb2', 'Cdk1', 'Nusap1', 'Ube2c', 'Birc5', 'Tpx2', 'Top2a', 'Ndc80', 'Cks2',\n",
    "    'Nuf2', 'Cks1b', 'Mki67', 'Tmpo', 'Cenpf', 'Tacc3', 'Fam64a', 'Smc4', 'Ccnb2',\n",
    "    'Ckap2l', 'Ckap2', 'Aurkb', 'Bub1', 'Kif11', 'Anp32e', 'Tubb4b', 'Gtse1',\n",
    "    'Kif20b', 'Hjurp', 'Cdca3', 'Cdc20', 'Ttk', 'Cdc25c', 'Kif2c', 'Rangap1',\n",
    "    'Ncapd2', 'Dlgap5', 'Cdca2', 'Cdca8', 'Ect2', 'Kif23', 'Hmmr', 'Aurka',\n",
    "    'Psrc1', 'Anln', 'Lbr', 'Ckap5', 'Cenpe', 'Ctcf', 'Nek2', 'G2e3', 'Gas2l3',\n",
    "    'Cbx5', 'Cenpa'\n",
    "]\n",
    "\n",
    "# Create normalized copy for cell cycle scoring\n",
    "adata_temp = adata.copy()\n",
    "sc.pp.normalize_total(adata_temp, target_sum=1e4)\n",
    "sc.pp.log1p(adata_temp)\n",
    "\n",
    "# Score cell cycle\n",
    "sc.tl.score_genes_cell_cycle(adata_temp, s_genes=s_genes, g2m_genes=g2m_genes)\n",
    "\n",
    "# Copy scores back to main object\n",
    "adata.obs['S_score'] = adata_temp.obs['S_score']\n",
    "adata.obs['G2M_score'] = adata_temp.obs['G2M_score']\n",
    "adata.obs['phase'] = adata_temp.obs['phase']\n",
    "\n",
    "print(\"\\nâœ… Cell cycle scoring completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772fc65e",
   "metadata": {},
   "source": [
    "### Compute QC Metrics\n",
    "Calculate QC metrics (MT%, ribo%, HB%) for the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aa19a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute QC metrics\n",
    "# Mouse genes: mt- (not MT-), Rps/Rpl, Hb\n",
    "adata.var[\"mt\"] = adata.var_names.str.startswith(\"mt-\")  # mitochondrial genes (mouse: mt-)\n",
    "adata.var[\"ribo\"] = adata.var_names.str.startswith((\"Rps\", \"Rpl\"))  # ribosomal genes\n",
    "adata.var[\"hb\"] = adata.var_names.str.contains(\"^Hb[abdefgh]\")  # hemoglobin genes\n",
    "\n",
    "sc.pp.calculate_qc_metrics(\n",
    "    adata, qc_vars=[\"mt\", \"ribo\", \"hb\"], inplace=True, log1p=False\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… QC metrics computed\")\n",
    "print(f\"Data shape: {adata.shape}\")\n",
    "print(f\"Library: {LIBRARY_NAME}\")\n",
    "print(f\"Batch: {BATCH_NAME}\")\n",
    "print(f\"Sex: {SEX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e424d754",
   "metadata": {},
   "source": [
    "### Prefiltered QC Plots\n",
    "Visualize QC metrics before any filtering to assess data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb0ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QC Violin plots\n",
    "sc.pl.violin(\n",
    "    adata,\n",
    "    [\"n_genes_by_counts\", \"total_counts\", \"pct_counts_mt\", \"pct_counts_ribo\", \"pct_counts_hb\"],\n",
    "    jitter=0.4,\n",
    "    multi_panel=True,\n",
    "    show=False\n",
    ")\n",
    "\n",
    "# Visualize the violin plots here in the notebook\n",
    "plt.show()\n",
    "\n",
    "fig = plt.gcf()\n",
    "png_path = png_dir / f\"{OUTPUT_PREFIX}_prefiltered_qc_violin.png\"\n",
    "pdf_path = pdf_dir / f\"{OUTPUT_PREFIX}_prefiltered_qc_violin.pdf\"\n",
    "\n",
    "try:\n",
    "    fig.savefig(png_path, dpi=600, bbox_inches='tight')\n",
    "    fig.savefig(pdf_path, dpi=600, bbox_inches='tight')\n",
    "    print(f\"Violin plot saved as:\\n- {png_path}\\n- {pdf_path}\")\n",
    "except Exception as e:\n",
    "    raise OSError(f\"Failed to save violin plots: {e}\")\n",
    "\n",
    "plt.close(fig)\n",
    "\n",
    "# QC Scatter plots (standard colorbars)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7), dpi=600)\n",
    "\n",
    "def simple_scatter(adata, x, y, color, ax, title):\n",
    "    sc.pl.scatter(\n",
    "        adata,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        color=color,\n",
    "        ax=ax,\n",
    "        size=10,\n",
    "        alpha=1.0,\n",
    "        show=False,\n",
    "        color_map='viridis',\n",
    "        legend_loc='right margin',\n",
    "        legend_fontoutline=2,\n",
    "        legend_fontsize='small'\n",
    "    )\n",
    "    ax.set_title(title)\n",
    "\n",
    "# Adjust layout to provide more space for colorbars\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(right=0.80)\n",
    "\n",
    "# First scatter\n",
    "simple_scatter(\n",
    "    adata,\n",
    "    x='total_counts',\n",
    "    y='n_genes_by_counts',\n",
    "    color='pct_counts_mt',\n",
    "    ax=axes[0],\n",
    "    title=\"n_genes_by_counts vs total_counts\"\n",
    ")\n",
    "\n",
    "# Second scatter\n",
    "simple_scatter(\n",
    "    adata,\n",
    "    x='pct_counts_mt',\n",
    "    y='pct_counts_ribo',\n",
    "    color='pct_counts_hb',\n",
    "    ax=axes[1],\n",
    "    title=\"pct_counts_mt vs pct_counts_ribo\"\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Save scatter plots\n",
    "scatter_png_path = png_dir / f\"{OUTPUT_PREFIX}_prefiltered_qc_scatter.png\"\n",
    "scatter_pdf_path = pdf_dir / f\"{OUTPUT_PREFIX}_prefiltered_qc_scatter.pdf\"\n",
    "\n",
    "try:\n",
    "    fig.savefig(scatter_png_path, dpi=600, bbox_inches='tight')\n",
    "    fig.savefig(scatter_pdf_path, dpi=600, bbox_inches='tight')\n",
    "    print(f\"Scatter plots saved as:\\n- {scatter_png_path}\\n- {scatter_pdf_path}\")\n",
    "except Exception as e:\n",
    "    raise OSError(f\"Failed to save scatter plots: {e}\")\n",
    "\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234981cb",
   "metadata": {},
   "source": [
    "### Intermediate Filtering and QC\n",
    "Apply intermediate filtering thresholds and visualize QC metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96766ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intermediate filters\n",
    "cutoffs = {\"min_genes\": 1000, \"max_counts\": 40000, \"max_pct_mt\": 20, \"min_pct_ribo\": 0.5}\n",
    "cutoff_text = (\n",
    "    f\"Cutoffs: n_genes_by_counts > {cutoffs['min_genes']} & total_counts < {cutoffs['max_counts']} & \"\n",
    "    f\"pct_counts_mt < {cutoffs['max_pct_mt']} & pct_counts_ribo > {cutoffs['min_pct_ribo']}\"\n",
    ")\n",
    "\n",
    "adata_filtered = adata[\n",
    "    (adata.obs[\"n_genes_by_counts\"] > cutoffs[\"min_genes\"]) &\n",
    "    (adata.obs[\"total_counts\"] < cutoffs[\"max_counts\"]) &\n",
    "    (adata.obs[\"pct_counts_mt\"] < cutoffs[\"max_pct_mt\"]) &\n",
    "    (adata.obs[\"pct_counts_ribo\"] > cutoffs[\"min_pct_ribo\"])\n",
    "].copy()\n",
    "print(f\"Filtered down to {adata_filtered.n_obs} cells (from {adata.n_obs}).\")\n",
    "\n",
    "# Violin\n",
    "sc.pl.violin(\n",
    "    adata_filtered,\n",
    "    [\"n_genes_by_counts\", \"total_counts\", \"pct_counts_mt\", \"pct_counts_ribo\", \"pct_counts_hb\"],\n",
    "    jitter=0.4,\n",
    "    multi_panel=True,\n",
    "    show=False,\n",
    ")\n",
    "\n",
    "# Visualize the violin plots here in the notebook\n",
    "plt.show()\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.subplots_adjust(bottom=0.15)\n",
    "fig.text(0.5, 0.01, cutoff_text, ha='center', fontsize=10, style='italic')\n",
    "\n",
    "violin_png_path = png_dir / f\"{OUTPUT_PREFIX}_intermediate_filter_qc_violin.png\"\n",
    "violin_pdf_path = pdf_dir / f\"{OUTPUT_PREFIX}_intermediate_filter_qc_violin.pdf\"\n",
    "\n",
    "try:\n",
    "    fig.savefig(violin_png_path, dpi=600, bbox_inches='tight')\n",
    "    fig.savefig(violin_pdf_path, dpi=600, bbox_inches='tight')\n",
    "    print(f\"Violin plots saved as:\\n- {violin_png_path}\\n- {violin_pdf_path}\")\n",
    "except Exception as e:\n",
    "    raise OSError(f\"Failed to save violin plots: {e}\")\n",
    "\n",
    "plt.close(fig)\n",
    "\n",
    "# Scatter plots (standard colorbars)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7), dpi=600)\n",
    "\n",
    "def simple_scatter(adata, x, y, color, ax, title):\n",
    "    sc.pl.scatter(\n",
    "        adata,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        color=color,\n",
    "        ax=ax,\n",
    "        size=10,\n",
    "        alpha=1.0,\n",
    "        show=False,\n",
    "        color_map='viridis',\n",
    "        legend_loc='right margin',\n",
    "        legend_fontoutline=2,\n",
    "        legend_fontsize='small'\n",
    "    )\n",
    "    ax.set_title(title)\n",
    "\n",
    "# Adjust layout to provide more space for colorbars\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(right=0.80, bottom=0.15)\n",
    "\n",
    "# First scatter\n",
    "simple_scatter(\n",
    "    adata_filtered,\n",
    "    x='total_counts',\n",
    "    y='n_genes_by_counts',\n",
    "    color='pct_counts_mt',\n",
    "    ax=axes[0],\n",
    "    title=\"n_genes_by_counts vs total_counts\"\n",
    ")\n",
    "\n",
    "# Second scatter\n",
    "simple_scatter(\n",
    "    adata_filtered,\n",
    "    x='pct_counts_mt',\n",
    "    y='pct_counts_ribo',\n",
    "    color='pct_counts_hb',\n",
    "    ax=axes[1],\n",
    "    title=\"pct_counts_mt vs pct_counts_ribo\"\n",
    ")\n",
    "\n",
    "# Add cutoff text\n",
    "fig.text(0.5, 0.01, cutoff_text, ha='center', fontsize=10, style='italic')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Save scatter plots\n",
    "scatter_png_path = png_dir / f\"{OUTPUT_PREFIX}_intermediate_filter_qc_scatter.png\"\n",
    "scatter_pdf_path = pdf_dir / f\"{OUTPUT_PREFIX}_intermediate_filter_qc_scatter.pdf\"\n",
    "\n",
    "try:\n",
    "    fig.savefig(scatter_png_path, dpi=600, bbox_inches='tight')\n",
    "    fig.savefig(scatter_pdf_path, dpi=600, bbox_inches='tight')\n",
    "    print(f\"Scatter plots saved as:\\n- {scatter_png_path}\\n- {scatter_pdf_path}\")\n",
    "except Exception as e:\n",
    "    raise OSError(f\"Failed to save scatter plots: {e}\")\n",
    "\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e589b1f",
   "metadata": {},
   "source": [
    "### Final Filtering and QC\n",
    "Apply final filtering thresholds and visualize QC metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da5116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final filters\n",
    "cutoffs = {\"min_genes\": 2000, \"max_counts\": 30000, \"max_pct_mt\": 6, \"min_pct_ribo\": 1.0}\n",
    "cutoff_text = (\n",
    "    f\"Cutoffs: n_genes_by_counts > {cutoffs['min_genes']} & total_counts < {cutoffs['max_counts']} & \"\n",
    "    f\"pct_counts_mt < {cutoffs['max_pct_mt']} & pct_counts_ribo > {cutoffs['min_pct_ribo']}\"\n",
    ")\n",
    "\n",
    "adata_filtered = adata[\n",
    "    (adata.obs[\"n_genes_by_counts\"] > cutoffs[\"min_genes\"]) &\n",
    "    (adata.obs[\"total_counts\"] < cutoffs[\"max_counts\"]) &\n",
    "    (adata.obs[\"pct_counts_mt\"] < cutoffs[\"max_pct_mt\"]) &\n",
    "    (adata.obs[\"pct_counts_ribo\"] > cutoffs[\"min_pct_ribo\"])\n",
    "].copy()\n",
    "print(f\"Filtered down to {adata_filtered.n_obs} cells (from {adata.n_obs}).\")\n",
    "\n",
    "# Violin\n",
    "sc.pl.violin(\n",
    "    adata_filtered,\n",
    "    [\"n_genes_by_counts\", \"total_counts\", \"pct_counts_mt\", \"pct_counts_ribo\", \"pct_counts_hb\"],\n",
    "    jitter=0.4,\n",
    "    multi_panel=True,\n",
    "    show=False,\n",
    ")\n",
    "\n",
    "# Visualize the violin plots here in the notebook\n",
    "plt.show()\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.subplots_adjust(bottom=0.15)\n",
    "fig.text(0.5, 0.01, cutoff_text, ha='center', fontsize=10, style='italic')\n",
    "\n",
    "violin_png_path = png_dir / f\"{OUTPUT_PREFIX}_final_filter_qc_violin.png\"\n",
    "violin_pdf_path = pdf_dir / f\"{OUTPUT_PREFIX}_final_filter_qc_violin.pdf\"\n",
    "\n",
    "try:\n",
    "    fig.savefig(violin_png_path, dpi=600, bbox_inches='tight')\n",
    "    fig.savefig(violin_pdf_path, dpi=600, bbox_inches='tight')\n",
    "    print(f\"Violin plots saved as:\\n- {violin_png_path}\\n- {violin_pdf_path}\")\n",
    "except Exception as e:\n",
    "    raise OSError(f\"Failed to save violin plots: {e}\")\n",
    "\n",
    "plt.close(fig)\n",
    "\n",
    "# Scatter plots (standard colorbars)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7), dpi=600)\n",
    "\n",
    "def simple_scatter(adata, x, y, color, ax, title):\n",
    "    sc.pl.scatter(\n",
    "        adata,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        color=color,\n",
    "        ax=ax,\n",
    "        size=10,\n",
    "        alpha=1.0,\n",
    "        show=False,\n",
    "        color_map='viridis',\n",
    "        legend_loc='right margin',\n",
    "        legend_fontoutline=2,\n",
    "        legend_fontsize='small'\n",
    "    )\n",
    "    ax.set_title(title)\n",
    "\n",
    "# Adjust layout to provide more space for colorbars\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(right=0.80, bottom=0.15)\n",
    "\n",
    "# First scatter\n",
    "simple_scatter(\n",
    "    adata_filtered,\n",
    "    x='total_counts',\n",
    "    y='n_genes_by_counts',\n",
    "    color='pct_counts_mt',\n",
    "    ax=axes[0],\n",
    "    title=\"n_genes_by_counts vs total_counts\"\n",
    ")\n",
    "\n",
    "# Second scatter\n",
    "simple_scatter(\n",
    "    adata_filtered,\n",
    "    x='pct_counts_mt',\n",
    "    y='pct_counts_ribo',\n",
    "    color='pct_counts_hb',\n",
    "    ax=axes[1],\n",
    "    title=\"pct_counts_mt vs pct_counts_ribo\"\n",
    ")\n",
    "\n",
    "# Add cutoff text\n",
    "fig.text(0.5, 0.01, cutoff_text, ha='center', fontsize=10, style='italic')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Save scatter plots\n",
    "scatter_png_path = png_dir / f\"{OUTPUT_PREFIX}_final_filter_qc_scatter.png\"\n",
    "scatter_pdf_path = pdf_dir / f\"{OUTPUT_PREFIX}_final_filter_qc_scatter.pdf\"\n",
    "\n",
    "try:\n",
    "    fig.savefig(scatter_png_path, dpi=600, bbox_inches='tight')\n",
    "    fig.savefig(scatter_pdf_path, dpi=600, bbox_inches='tight')\n",
    "    print(f\"Scatter plots saved as:\\n- {scatter_png_path}\\n- {scatter_pdf_path}\")\n",
    "except Exception as e:\n",
    "    raise OSError(f\"Failed to save scatter plots: {e}\")\n",
    "\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05eda0ea",
   "metadata": {},
   "source": [
    "### HTO Classification Summary (if applicable)\n",
    "Review HTO demultiplexing assignments after final filtering (only if HashSolo was run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b361ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTO assignment summary (post-filter) - only if HashSolo was run\n",
    "if USE_HASHSOLO and has_hto:\n",
    "    print(\"\\n--- HTO classification (filtered) ---\")\n",
    "    print(adata_filtered.obs['Classification'].value_counts())\n",
    "    print(f\"\\nUnique classifications: {adata_filtered.obs['Classification'].unique()}\")\n",
    "    print(f\"\\nmost_likely_hypothesis:\")\n",
    "    print(adata_filtered.obs['most_likely_hypothesis'].value_counts())\n",
    "    \n",
    "    # QC by HTO class - Violin plots\n",
    "    qc_df = adata_filtered.obs[['n_genes_by_counts', 'total_counts', 'Classification']].copy()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5), dpi=300)\n",
    "    \n",
    "    # First violin plot with dots\n",
    "    sns.violinplot(data=qc_df, x='Classification', y='n_genes_by_counts', ax=axes[0], \n",
    "                   inner='quartile', hue='Classification', legend=False,\n",
    "                   cut=0, scale='count', bw_adjust=0.5)\n",
    "    sns.stripplot(data=qc_df, x='Classification', y='n_genes_by_counts', ax=axes[0], \n",
    "                  color='black', alpha=0.4, size=1.5, jitter=True)\n",
    "    axes[0].set_title(\"n_genes_by_counts by Classification\"); axes[0].tick_params(axis='x', rotation=90)\n",
    "    \n",
    "    # Second violin plot with dots\n",
    "    sns.violinplot(data=qc_df, x='Classification', y='total_counts', ax=axes[1], \n",
    "                   inner='quartile', hue='Classification', legend=False,\n",
    "                   cut=0, scale='count', bw_adjust=0.5)\n",
    "    sns.stripplot(data=qc_df, x='Classification', y='total_counts', ax=axes[1], \n",
    "                  color='black', alpha=0.4, size=1.5, jitter=True)\n",
    "    axes[1].set_title(\"total_counts by Classification\"); axes[1].tick_params(axis='x', rotation=90)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.savefig(pdf_dir / f\"{OUTPUT_PREFIX}_post_demux_qc_violin.pdf\", bbox_inches='tight')\n",
    "    fig.savefig(png_dir / f\"{OUTPUT_PREFIX}_post_demux_qc_violin.png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Saved post-demux QC violin plots\")\n",
    "    \n",
    "    # CLR normalize HTO data for ridgeplot\n",
    "    print(\"\\n--- CLR normalizing HTO data for visualization ---\")\n",
    "    hto_features = adata_filtered.uns['HTO_features']\n",
    "    hto_columns = [f\"HTO_{hto}\" for hto in hto_features]\n",
    "    \n",
    "    # Extract HTO counts matrix\n",
    "    hto_matrix = adata_filtered.obs[hto_columns].values\n",
    "    \n",
    "    # CLR normalization: log(x / geometric_mean(x))\n",
    "    # Add pseudocount to avoid log(0)\n",
    "    hto_matrix_pseudo = hto_matrix + 1\n",
    "    geometric_mean = np.exp(np.mean(np.log(hto_matrix_pseudo), axis=1, keepdims=True))\n",
    "    hto_clr = np.log(hto_matrix_pseudo / geometric_mean)\n",
    "    \n",
    "    # Add CLR-normalized HTO columns\n",
    "    for i, hto in enumerate(hto_features):\n",
    "        adata_filtered.obs[f\"HTO_{hto}_CLR\"] = hto_clr[:, i]\n",
    "    \n",
    "    print(\"âœ… CLR normalization completed\")\n",
    "    \n",
    "    # Ridgeplot of CLR-normalized HTO expression\n",
    "    print(\"\\n--- Creating HTO ridgeplot (CLR-normalized) ---\")\n",
    "    \n",
    "    # Get all classifications sorted (excluding Not_demultiplexed and Negative)\n",
    "    all_classifications = sorted([c for c in adata_filtered.obs['Classification'].unique() \n",
    "                                 if c not in ['Not_demultiplexed', 'Negative']])\n",
    "    \n",
    "    # Create ridgeplot layout: 2 columns, 3 rows (total 6 HTOs)\n",
    "    n_htos = len(hto_features)\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(14, 10), dpi=300)\n",
    "    axes = axes.flatten()  # Flatten to 1D for easier iteration\n",
    "    \n",
    "    for i, hto in enumerate(hto_features):\n",
    "        ax = axes[i]\n",
    "        hto_col_clr = f\"HTO_{hto}_CLR\"\n",
    "        \n",
    "        # Plot all classifications (singlets + doublets, excluding Negative)\n",
    "        for classification in all_classifications:\n",
    "            subset = adata_filtered.obs[adata_filtered.obs['Classification'] == classification]\n",
    "            if len(subset) > 0:\n",
    "                data = subset[hto_col_clr].values\n",
    "                # Use different color for doublet\n",
    "                color = 'red' if classification == 'Doublet' else None\n",
    "                label = classification\n",
    "                sns.kdeplot(data=data, ax=ax, label=label, fill=True, alpha=0.5, \n",
    "                           linewidth=1.5, color=color if color else None)\n",
    "        \n",
    "        ax.set_xlabel(f'{hto} CLR-normalized counts', fontsize=10)\n",
    "        ax.set_ylabel('Density', fontsize=10)\n",
    "        ax.set_title(f'Distribution of {hto} (CLR)', fontsize=11, fontweight='bold')\n",
    "        ax.legend(loc='upper right', fontsize=7)\n",
    "        ax.axvline(x=0, color='gray', linestyle='--', alpha=0.5, linewidth=1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    ridge_png_path = png_dir / f\"{OUTPUT_PREFIX}_hto_ridgeplot_clr.png\"\n",
    "    ridge_pdf_path = pdf_dir / f\"{OUTPUT_PREFIX}_hto_ridgeplot_clr.pdf\"\n",
    "    \n",
    "    fig.savefig(ridge_png_path, dpi=600, bbox_inches='tight')\n",
    "    fig.savefig(ridge_pdf_path, dpi=600, bbox_inches='tight')\n",
    "    print(f\"HTO ridgeplot saved as:\\n- {ridge_png_path}\\n- {ridge_pdf_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "    \n",
    "else:\n",
    "    print(\"\\nâ­ï¸  Skipping HTO classification summary (HashSolo not run)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00be2916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barplot: Cell counts per HTO classification (singlets only) - only if HashSolo was run\n",
    "if USE_HASHSOLO and has_hto:\n",
    "    # Get value counts\n",
    "    classification_counts = adata_filtered.obs['Classification'].value_counts()\n",
    "    \n",
    "    # Get all unique classifications and filter to those that exist (excluding Doublet and Negative)\n",
    "    all_classifications = [c for c in classification_counts.index.tolist() if c not in ['Doublet', 'Negative', 'Not_demultiplexed']]\n",
    "    \n",
    "    # Sort classifications\n",
    "    singlet_order = sorted(all_classifications)\n",
    "    \n",
    "    # Reorder counts (only singlets)\n",
    "    ordered_counts = classification_counts.reindex(singlet_order)\n",
    "    \n",
    "    # Create barplot\n",
    "    fig, ax = plt.subplots(figsize=(8, 5), dpi=300)\n",
    "    \n",
    "    bars = ax.bar(range(len(ordered_counts)), ordered_counts.values, color='#1f77b4')\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_xlabel('HTO Classification', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Cell Count', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Cell Counts per HTO Classification (Singlets Only)', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(range(len(ordered_counts)))\n",
    "    ax.set_xticklabels(ordered_counts.index, rotation=45, ha='right')\n",
    "    \n",
    "    # Add value labels on top of bars\n",
    "    for i, (bar, count) in enumerate(zip(bars, ordered_counts.values)):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(count)}',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # Add grid for better readability\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax.set_axisbelow(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    barplot_png_path = png_dir / f\"{OUTPUT_PREFIX}_hto_classification_barplot.png\"\n",
    "    barplot_pdf_path = pdf_dir / f\"{OUTPUT_PREFIX}_hto_classification_barplot.pdf\"\n",
    "    \n",
    "    try:\n",
    "        fig.savefig(barplot_png_path, dpi=600, bbox_inches='tight')\n",
    "        fig.savefig(barplot_pdf_path, dpi=600, bbox_inches='tight')\n",
    "        print(f\"Barplot saved as:\\n- {barplot_png_path}\\n- {barplot_pdf_path}\")\n",
    "    except Exception as e:\n",
    "        raise OSError(f\"Failed to save barplot: {e}\")\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Print summary (singlets only)\n",
    "    print(\"\\n--- Cell counts per HTO classification (singlets only) ---\")\n",
    "    for label, count in ordered_counts.items():\n",
    "        print(f\"{label}: {count}\")\n",
    "else:\n",
    "    print(\"\\nâ­ï¸  Skipping HTO barplot (HashSolo not run)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a097d1",
   "metadata": {},
   "source": [
    "### Save QC-Filtered Data\n",
    "Save the QC-filtered AnnData object before clustering. If HashSolo was run, keep only singlets. This is the clean, quality-controlled dataset with raw counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb8f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine filtereddataset to save\n",
    "if USE_HASHSOLO and has_hto:\n",
    "    # Keep singlets only (drop doublets and negatives)\n",
    "    all_classifications = adata_filtered.obs['Classification'].unique()\n",
    "    singlet_labels = [c for c in all_classifications if c not in ['Doublet', 'Negative']]\n",
    "    \n",
    "    print(f\"Singlet labels: {singlet_labels}\")\n",
    "    \n",
    "    adata_final = adata_filtered[adata_filtered.obs[\"Classification\"].isin(singlet_labels)].copy()\n",
    "    print(f\"\\nFiltered from {adata_filtered.n_obs} to {adata_final.n_obs} singlet cells\")\n",
    "    \n",
    "    # Save singlets\n",
    "    output_file = results_dir / f\"{OUTPUT_PREFIX}_adata_qc_singlets.h5ad\"\n",
    "    adata_final.write(output_file)\n",
    "    print(f\"\\nâœ… Saved singlets-only AnnData with {adata_final.n_obs} cells to:\\n{output_file}\")\n",
    "else:\n",
    "    # No HashSolo - just save the QC-filtered data\n",
    "    adata_final = adata_filtered.copy()\n",
    "    \n",
    "    # Save filtered data\n",
    "    output_file = results_dir / f\"{OUTPUT_PREFIX}_adata_qc_filtered.h5ad\"\n",
    "    adata_final.write(output_file)\n",
    "    print(f\"\\nâœ… Saved QC-filtered AnnData with {adata_final.n_obs} cells to:\\n{output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f275469",
   "metadata": {},
   "source": [
    "## Clustering and Visualization for Contamination Detection\n",
    "\n",
    "### Purpose\n",
    "Perform quick clustering and visualization to identify and filter out contaminating cells (non-microglia cells). After reviewing the clusters and marker gene expression, you can select only microglia cells for downstream scVI integration.\n",
    "\n",
    "**Important**: Raw counts are preserved in `adata.layers['counts']` while normalized data is used for visualization only. This ensures compatibility with scVI integration in the next step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3974460",
   "metadata": {},
   "source": [
    "### Store Raw Counts and Normalize for Visualization\n",
    "Preserve raw counts in a layer, then normalize and log-transform the data for clustering and visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea8e23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store raw counts in a layer for future scVI integration\n",
    "adata_final.layers['counts'] = adata_final.X.copy()\n",
    "print(f\"âœ“ Stored raw counts in adata.layers['counts']\")\n",
    "\n",
    "# Normalize and log-transform for visualization\n",
    "# This modifies adata.X but raw counts remain in adata.layers['counts']\n",
    "sc.pp.normalize_total(adata_final, target_sum=1e4)\n",
    "sc.pp.log1p(adata_final)\n",
    "print(f\"âœ“ Normalized to 10,000 counts per cell\")\n",
    "print(f\"âœ“ Log-transformed (log1p)\")\n",
    "\n",
    "# Verify the data state\n",
    "max_val = adata_final.X.max() if hasattr(adata_final.X, 'max') else adata_final.X.data.max()\n",
    "print(f\"\\nâœ“ Normalized X matrix max value: {max_val:.2f}\")\n",
    "print(f\"âœ“ Raw counts preserved in adata.layers['counts']\")\n",
    "print(f\"âœ“ X matrix will be used for clustering and visualization only\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9662d7",
   "metadata": {},
   "source": [
    "### Highly Variable Genes, PCA, and Clustering\n",
    "Identify highly variable genes, compute PCA, construct neighbor graph, and perform Leiden clustering at multiple resolutions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e899c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "n_top_genes = 3000\n",
    "n_pcs = 50\n",
    "n_neighbors = 30\n",
    "\n",
    "# Clustering resolutions to test\n",
    "clustering_resolutions = [0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0, 2.2, 2.4, 2.6, 2.8, 3.0]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"HIGHLY VARIABLE GENES AND PCA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Identify highly variable genes\n",
    "sc.pp.highly_variable_genes(adata_final, n_top_genes=n_top_genes, flavor='seurat_v3', layer='counts')\n",
    "print(f\"âœ“ Identified {adata_final.var['highly_variable'].sum()} highly variable genes\")\n",
    "\n",
    "# Regress out cell cycle effects\n",
    "print(f\"\\nâœ“ Regressing out cell cycle effects (S_score, G2M_score)...\")\n",
    "sc.pp.regress_out(adata_final, ['S_score', 'G2M_score'])\n",
    "print(f\"âœ“ Cell cycle effects regressed out\")\n",
    "\n",
    "# Scale data to unit variance and zero mean\n",
    "print(f\"âœ“ Scaling data...\")\n",
    "sc.pp.scale(adata_final, max_value=10)\n",
    "print(f\"âœ“ Data scaled (max_value=10)\")\n",
    "\n",
    "# Compute PCA on scaled data using HVGs\n",
    "sc.tl.pca(adata_final, n_comps=n_pcs, use_highly_variable=True)\n",
    "print(f\"âœ“ Computed PCA: {adata_final.obsm['X_pca'].shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"NEIGHBOR GRAPH AND UMAP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Compute neighbors\n",
    "sc.pp.neighbors(adata_final, n_neighbors=n_neighbors, n_pcs=n_pcs)\n",
    "print(f\"âœ“ Computed neighbor graph (k={n_neighbors}, n_pcs={n_pcs})\")\n",
    "\n",
    "# Compute UMAP\n",
    "sc.tl.umap(adata_final)\n",
    "print(f\"âœ“ Computed UMAP: {adata_final.obsm['X_umap'].shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LEIDEN CLUSTERING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Perform Leiden clustering at multiple resolutions\n",
    "for res in clustering_resolutions:\n",
    "    key = f'leiden_r{res}'\n",
    "    sc.tl.leiden(adata_final, resolution=res, key_added=key, flavor=\"igraph\", \n",
    "                 n_iterations=2, directed=False)\n",
    "    n_clusters = len(adata_final.obs[key].cat.categories)\n",
    "    print(f'âœ“ Resolution {res:4.1f} -> {n_clusters:3d} clusters (adata.obs[\"{key}\"])')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22603171",
   "metadata": {},
   "source": [
    "### Visualization: Multi-Resolution Clustering Overview\n",
    "Visualize clustering results across all resolutions to identify optimal granularity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011f18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# USER CONFIGURATION\n",
    "# ============================================================\n",
    "point_size = 20         # Size of points in UMAP\n",
    "n_cols_grid = 7         # Number of columns in grid layout\n",
    "plot_name = 'leiden_clustering_overview'\n",
    "color_palette = 'husl'  # Color palette for clusters (options: 'husl', 'tab20', 'Set3', etc.)\n",
    "\n",
    "# Resolutions to visualize (already defined earlier)\n",
    "# clustering_resolutions = [0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0, 2.2, 2.4, 2.6, 2.8, 3.0]\n",
    "\n",
    "# ============================================================\n",
    "# GENERATE MULTI-RESOLUTION PLOT\n",
    "# ============================================================\n",
    "\n",
    "# Verify UMAP exists\n",
    "if 'X_umap' not in adata_final.obsm:\n",
    "    raise ValueError(\"X_umap not found. Run clustering section first.\")\n",
    "\n",
    "# Get clustering columns\n",
    "clustering_keys = [f'leiden_r{res}' for res in clustering_resolutions]\n",
    "missing_keys = [key for key in clustering_keys if key not in adata_final.obs]\n",
    "if missing_keys:\n",
    "    raise ValueError(f\"Missing clustering results: {missing_keys}\")\n",
    "\n",
    "# Setup grid layout\n",
    "n_rows = (len(clustering_resolutions) + n_cols_grid - 1) // n_cols_grid\n",
    "fig, axes = plt.subplots(n_rows, n_cols_grid, \n",
    "                         figsize=(3 * n_cols_grid, 3 * n_rows), \n",
    "                         sharex=True, sharey=True, dpi=300)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Import for color palette conversion\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Plot each resolution\n",
    "for i, res in enumerate(clustering_resolutions):\n",
    "    key = f'leiden_r{res}'\n",
    "    n_clusters = len(adata_final.obs[key].cat.categories)\n",
    "    \n",
    "    # Set up custom color palette for publication quality\n",
    "    custom_palette = sns.color_palette(color_palette, n_clusters)\n",
    "    adata_final.uns[f'{key}_colors'] = [mcolors.to_hex(c) for c in custom_palette]\n",
    "    \n",
    "    sc.pl.umap(\n",
    "        adata_final,\n",
    "        color=key,\n",
    "        ax=axes[i],\n",
    "        show=False,\n",
    "        title=f'Resolution {res} ({n_clusters} clusters)',\n",
    "        legend_loc='on data',\n",
    "        frameon=False,\n",
    "        size=point_size,\n",
    "        palette=adata_final.uns[f'{key}_colors']\n",
    "    )\n",
    "\n",
    "# Hide unused subplots\n",
    "for j in range(len(clustering_resolutions), len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "plt.suptitle(\"Leiden Clustering at Multiple Resolutions\", y=1.02, fontsize=18)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plots\n",
    "fig.savefig(png_dir / f\"{OUTPUT_PREFIX}_{plot_name}.png\", dpi=300, bbox_inches='tight')\n",
    "fig.savefig(pdf_dir / f\"{OUTPUT_PREFIX}_{plot_name}.pdf\", bbox_inches='tight')\n",
    "print(f\"âœ“ Saved {plot_name}\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f340be3",
   "metadata": {},
   "source": [
    "### Selected Resolution Clustering\n",
    "Visualize clustering results at a specific resolution for detailed inspection. Choose your preferred resolution based on the multi-resolution overview above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3219267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure inline plotting in Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "# ============================================================\n",
    "# USER CONFIGURATION - SINGLE RESOLUTION\n",
    "# ============================================================\n",
    "selected_resolution = 1.0  # ðŸ‘ˆ Change this to your desired resolution\n",
    "point_size = 40            # ðŸ‘ˆ Size of points in UMAP\n",
    "plot_width = 5            # ðŸ‘ˆ Figure width (in inches)\n",
    "plot_height = 5            # ðŸ‘ˆ Figure height (in inches)\n",
    "color_palette = 'husl'     # Color palette for clusters (options: 'husl', 'tab20', 'Set3', etc.)\n",
    "show_legend_on_data = True # ðŸ‘ˆ Show cluster numbers on UMAP (True) or in legend box (False)\n",
    "\n",
    "# ============================================================\n",
    "# VERIFY CLUSTERING EXISTS\n",
    "# ============================================================\n",
    "\n",
    "cluster_key = f'leiden_r{selected_resolution}'\n",
    "\n",
    "if cluster_key not in adata_final.obs:\n",
    "    available_leiden = [col for col in adata_final.obs.columns if col.startswith('leiden_r')]\n",
    "    available_res = [float(col.replace('leiden_r', '')) for col in available_leiden]\n",
    "    raise ValueError(\n",
    "        f\"Clustering column '{cluster_key}' not found.\\n\"\n",
    "        f\"Available resolutions: {sorted(available_res)}\"\n",
    "    )\n",
    "\n",
    "if 'X_umap' not in adata_final.obsm:\n",
    "    raise ValueError(\"X_umap not found. Run clustering section first.\")\n",
    "\n",
    "# Get cluster information\n",
    "n_clusters = len(adata_final.obs[cluster_key].cat.categories)\n",
    "print(f\"âœ“ Plotting clustering at resolution {selected_resolution}\")\n",
    "print(f\"  Clusters: {n_clusters}\")\n",
    "print(f\"  Total cells: {adata_final.n_obs:,}\")\n",
    "\n",
    "# ============================================================\n",
    "# GENERATE SINGLE RESOLUTION PLOT\n",
    "# ============================================================\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Set up custom color palette\n",
    "custom_palette = sns.color_palette(color_palette, n_clusters)\n",
    "adata_final.uns[f'{cluster_key}_colors'] = [mcolors.to_hex(c) for c in custom_palette]\n",
    "\n",
    "# Configure plot style\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "sns.set_style('white')\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(plot_width, plot_height), dpi=300)\n",
    "\n",
    "# Plot UMAP\n",
    "sc.pl.umap(\n",
    "    adata_final,\n",
    "    color=cluster_key,\n",
    "    ax=ax,\n",
    "    show=False,\n",
    "    title=f'Leiden Clustering (Resolution {selected_resolution}, n={n_clusters} clusters)',\n",
    "    legend_loc='on data' if show_legend_on_data else 'right margin',\n",
    "    frameon=False,\n",
    "    size=point_size,\n",
    "    palette=adata_final.uns[f'{cluster_key}_colors']\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plots with resolution in filename\n",
    "plot_name = f'leiden_clustering_r{selected_resolution}'\n",
    "png_path = png_dir / f'{OUTPUT_PREFIX}_{plot_name}.png'\n",
    "pdf_path = pdf_dir / f'{OUTPUT_PREFIX}_{plot_name}.pdf'\n",
    "\n",
    "fig.savefig(png_path, dpi=300, bbox_inches='tight')\n",
    "fig.savefig(pdf_path, bbox_inches='tight')\n",
    "\n",
    "print(f'\\nâœ“ Saved: {plot_name}.png/.pdf')\n",
    "print(f'  PNG: {png_path}')\n",
    "print(f'  PDF: {pdf_path}')\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(f'\\nâœ“ Visualization complete')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d88091",
   "metadata": {},
   "source": [
    "### Visualization: QC Metrics per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1046452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# USER CONFIGURATION - QC METRICS\n",
    "# ============================================================\n",
    "point_size = 20         # Size of points in UMAP\n",
    "n_cols_grid = 3         # Number of columns in grid layout\n",
    "plot_name = 'qc_metrics_umap'\n",
    "\n",
    "# QC variables to visualize\n",
    "qc_vars = ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', \n",
    "           'pct_counts_ribo', 'pct_counts_hb']\n",
    "\n",
    "# ============================================================\n",
    "# GENERATE QC METRICS PLOT\n",
    "# ============================================================\n",
    "\n",
    "# Verify UMAP exists\n",
    "if 'X_umap' not in adata_final.obsm:\n",
    "    raise ValueError(\"X_umap not found. Run clustering section first.\")\n",
    "\n",
    "# Setup grid layout\n",
    "n_rows = (len(qc_vars) + n_cols_grid - 1) // n_cols_grid\n",
    "fig, axes = plt.subplots(n_rows, n_cols_grid, \n",
    "                         figsize=(3 * n_cols_grid, 3 * n_rows), \n",
    "                         sharex=True, sharey=True, dpi=300)\n",
    "axes = axes.flatten()\n",
    "\n",
    "print(\"âœ“ Visualizing QC metrics on UMAP...\")\n",
    "\n",
    "# Plot each QC variable\n",
    "for i, var in enumerate(qc_vars):\n",
    "    sc.pl.umap(adata_final, color=var, ax=axes[i], show=False, \n",
    "               frameon=False, size=point_size)\n",
    "\n",
    "# Hide unused subplots\n",
    "for j in range(len(qc_vars), len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "plt.suptitle(\"QC Metrics\", y=1.02, fontsize=18)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plots\n",
    "fig.savefig(png_dir / f\"{OUTPUT_PREFIX}_{plot_name}.png\", dpi=300, bbox_inches='tight')\n",
    "fig.savefig(pdf_dir / f\"{OUTPUT_PREFIX}_{plot_name}.pdf\", bbox_inches='tight')\n",
    "print(f\"âœ“ Saved {plot_name}\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2f03e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure inline plotting in Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "# ============================================================\n",
    "# USER CONFIGURATION - MARKER GENES\n",
    "# ============================================================\n",
    "# Plot dimensions and style\n",
    "point_size = 10         # Size of points in UMAP\n",
    "n_cols_grid = 8         # Number of columns in grid layout\n",
    "plot_width = 15         # Figure width (in inches)\n",
    "plot_height = 8        # Figure height (in inches)\n",
    "plot_name = 'marker_genes_umap'\n",
    "\n",
    "# Colormap options:\n",
    "# - 'grey_plasma': Custom grey-to-plasma (zero expression = grey, high = plasma colors)\n",
    "# - 'viridis', 'plasma', 'magma', 'Blues', 'Reds' (standard matplotlib colormaps)\n",
    "use_custom_colormap = True  # ðŸ‘ˆ Set to False to use standard colormap below\n",
    "standard_colormap = 'viridis'  # Used if use_custom_colormap = False\n",
    "\n",
    "# Marker genes for different cell types (mouse gene symbols)\n",
    "marker_genes_dict = {\n",
    "    # General immune markers\n",
    "    'General': [\n",
    "        'Ptprc',  # CD45 - all immune cells\n",
    "        'Mki67',  # Proliferation marker\n",
    "        'Itgam'   # CD11b - myeloid cells\n",
    "    ],\n",
    "    # Microglia markers\n",
    "    'Microglia': [\n",
    "        'Cx3cr1',  # Fractalkine receptor\n",
    "        'P2ry12',  # Purinergic receptor\n",
    "        'Tmem119', # Microglia-specific\n",
    "        'Trem2'    # Homeostatic microglia\n",
    "    ],\n",
    "    # Macrophage markers\n",
    "    'Macrophages/BAMs': [\n",
    "        'Mrc1',    # CD206\n",
    "        'Ccr2',    # CCR2\n",
    "        'Ly6c2',\n",
    "        'Ms4a7',\n",
    "        'Pf4'    \n",
    "    ],\n",
    "    # T cell markers\n",
    "    'T cells': [\n",
    "        'Cd3e',    # CD3 epsilon\n",
    "        'Cd3d',    # CD3 delta\n",
    "        'Cd4',     # CD4+ T cells\n",
    "        'Cd8b1'    # CD8 beta\n",
    "    ],\n",
    "    # B cell markers\n",
    "    'B cells': [\n",
    "        'Cd79a',   # B cell receptor component\n",
    "        'Ms4a1',   # CD20\n",
    "        'Cd19',    # B cell marker\n",
    "        'Cd79b'    # B cell receptor component\n",
    "    ],\n",
    "    # NK cell markers\n",
    "    'NK cells': [\n",
    "        'Ncr1',    # NKp46\n",
    "        'Nkg7',    # NK granule protein\n",
    "        'Klrb1c',  # NK1.1\n",
    "        'Klrd1'    # CD94\n",
    "    ],\n",
    "    # Neuron markers\n",
    "    'Neurons': [\n",
    "        'Rbfox3',  # NeuN\n",
    "        'Tubb3',   # Beta-3 tubulin\n",
    "        'Syt1',    # Synaptotagmin\n",
    "        'Map2'     # Microtubule-associated protein 2\n",
    "    ],\n",
    "    # Astrocyte markers\n",
    "    'Astrocytes': [\n",
    "        'Gfap',    # Glial fibrillary acidic protein\n",
    "        'Aldh1l1', # Aldehyde dehydrogenase\n",
    "        'Aqp4',    # Aquaporin 4\n",
    "        'S100b'    # Astrocyte marker\n",
    "    ],\n",
    "    # Oligodendrocyte markers\n",
    "    'Oligodendrocytes': [\n",
    "        'Mbp',     # Myelin basic protein\n",
    "        'Mog',     # Myelin oligodendrocyte glycoprotein\n",
    "        'Plp1',    # Proteolipid protein 1\n",
    "        'Cnp'      # 2',3'-cyclic nucleotide 3'-phosphodiesterase\n",
    "    ],\n",
    "    # Endothelial markers\n",
    "    'Endothelial': [\n",
    "        'Pecam1',  # CD31\n",
    "        'Vwf',     # von Willebrand factor\n",
    "        'Cdh5',    # VE-cadherin\n",
    "        'Flt1'     # VEGFR1\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# CREATE CUSTOM GREY-PLASMA COLORMAP\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "if use_custom_colormap:\n",
    "    # Get plasma_r colormap\n",
    "    plasma_r = plt.cm.plasma_r\n",
    "    n_colors = 256\n",
    "    plasma_colors = plasma_r(np.linspace(0, 1, n_colors))\n",
    "    \n",
    "    # Replace first 20% with grey gradient\n",
    "    grey_to_plasma_transition = 0.2\n",
    "    n_grey_colors = int(n_colors * grey_to_plasma_transition)\n",
    "    \n",
    "    # Create grey gradient from light grey to first plasma color\n",
    "    light_grey = np.array([0.85, 0.85, 0.85, 1.0])\n",
    "    transition_color = plasma_colors[n_grey_colors]\n",
    "    grey_gradient = np.linspace(light_grey, transition_color, n_grey_colors)\n",
    "    \n",
    "    # Combine grey gradient with plasma_r\n",
    "    custom_colors = np.vstack([grey_gradient, plasma_colors[n_grey_colors:]])\n",
    "    colormap = LinearSegmentedColormap.from_list('grey_plasma', custom_colors)\n",
    "    \n",
    "    print('âœ“ Created custom grey-plasma colormap for gene expression')\n",
    "else:\n",
    "    colormap = standard_colormap\n",
    "    print(f'âœ“ Using standard colormap: {colormap}')\n",
    "\n",
    "# ============================================================\n",
    "# VERIFY DATA AND LAYERS\n",
    "# ============================================================\n",
    "\n",
    "# Verify UMAP exists\n",
    "if 'X_umap' not in adata_final.obsm:\n",
    "    raise ValueError(\"X_umap not found. Run clustering section first.\")\n",
    "\n",
    "# Check data normalization status\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA LAYER VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "max_val = adata_final.X.max() if hasattr(adata_final.X, 'max') else adata_final.X.data.max()\n",
    "print(f\"adata_final.X max value: {max_val:.2f}\")\n",
    "\n",
    "# Verify normalized data is being used\n",
    "if max_val > 50:\n",
    "    raise ValueError(\n",
    "        f\"adata_final.X appears to contain raw counts (max={max_val:.0f}). \"\n",
    "        \"Expected normalized/log-transformed data (max < 20). \"\n",
    "        \"Please run the normalization step first.\"\n",
    "    )\n",
    "else:\n",
    "    print(f\"âœ“ adata_final.X contains normalized, log-transformed data (max={max_val:.2f})\")\n",
    "\n",
    "# Check available layers\n",
    "print(f\"\\nAvailable layers: {list(adata_final.layers.keys())}\")\n",
    "if 'counts' in adata_final.layers:\n",
    "    print(\"âœ“ Raw counts preserved in adata.layers['counts']\")\n",
    "\n",
    "# Specify which data to use for plotting\n",
    "use_layer = None  # None = use adata.X (normalized, log-transformed)\n",
    "print(f\"\\nâœ“ Will use adata_final.X for gene expression visualization\")\n",
    "print(f\"  (normalized, log-transformed data)\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# VERIFY GENES\n",
    "# ============================================================\n",
    "\n",
    "# Flatten all marker genes into a single list\n",
    "all_marker_genes = []\n",
    "for cell_type, genes in marker_genes_dict.items():\n",
    "    all_marker_genes.extend(genes)\n",
    "\n",
    "# Check which genes are available in the dataset\n",
    "available_genes = [g for g in all_marker_genes if g in adata_final.var_names]\n",
    "missing_genes = [g for g in all_marker_genes if g not in adata_final.var_names]\n",
    "\n",
    "# Report available markers by cell type\n",
    "print(\"=\" * 60)\n",
    "print(\"MARKER GENE AVAILABILITY\")\n",
    "print(\"=\" * 60)\n",
    "available_by_type = {}\n",
    "for cell_type, genes in marker_genes_dict.items():\n",
    "    available = [g for g in genes if g in adata_final.var_names]\n",
    "    if available:\n",
    "        available_by_type[cell_type] = available\n",
    "        print(f\"\\n{cell_type}:\")\n",
    "        print(f\"  Available: {', '.join(available)}\")\n",
    "        missing_type = [g for g in genes if g not in adata_final.var_names]\n",
    "        if missing_type:\n",
    "            print(f\"  Missing: {', '.join(missing_type)}\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"SUMMARY:\")\n",
    "print(f\"  Total marker genes defined: {len(all_marker_genes)}\")\n",
    "print(f\"  Available in dataset: {len(available_genes)}\")\n",
    "print(f\"  Missing from dataset: {len(missing_genes)}\")\n",
    "if missing_genes:\n",
    "    print(f\"  Missing genes: {', '.join(missing_genes)}\")\n",
    "print(f\"{'=' * 60}\\n\")\n",
    "\n",
    "if not available_genes:\n",
    "    raise ValueError('No valid marker genes found in dataset for plotting.')\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURE PLOT STYLE\n",
    "# ============================================================\n",
    "\n",
    "# Ensure consistent styling\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "sns.set_style('white')\n",
    "\n",
    "# ============================================================\n",
    "# GENERATE MARKER GENES UMAP\n",
    "# ============================================================\n",
    "\n",
    "print(\"âœ“ Generating marker gene UMAP plots...\")\n",
    "\n",
    "n_genes = len(available_genes)\n",
    "n_rows = (n_genes + n_cols_grid - 1) // n_cols_grid\n",
    "\n",
    "# Calculate figure size based on grid\n",
    "fig, axes = plt.subplots(n_rows, n_cols_grid, \n",
    "                         figsize=(plot_width, plot_height),\n",
    "                         sharex=True, sharey=True, dpi=300)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each marker gene using normalized data\n",
    "for i, gene in enumerate(available_genes):\n",
    "    sc.pl.umap(adata_final, \n",
    "               color=gene, \n",
    "               ax=axes[i], \n",
    "               show=False, \n",
    "               title=gene, \n",
    "               frameon=False, \n",
    "               cmap=colormap,  # Use custom grey-plasma or standard colormap\n",
    "               size=point_size,\n",
    "               layer=use_layer,  # None = use adata.X (normalized)\n",
    "               vmin=0)  # Start colormap at 0\n",
    "\n",
    "# Hide unused subplots\n",
    "for j in range(len(available_genes), len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "colormap_name = 'Grey-Plasma' if use_custom_colormap else standard_colormap.title()\n",
    "plt.suptitle(f\"Cell Type Marker Genes Expression (Normalized, {colormap_name})\", \n",
    "             y=1.005, fontsize=22, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plots\n",
    "png_path = png_dir / f\"{OUTPUT_PREFIX}_{plot_name}.png\"\n",
    "pdf_path = pdf_dir / f\"{OUTPUT_PREFIX}_{plot_name}.pdf\"\n",
    "fig.savefig(png_path, dpi=300, bbox_inches='tight')\n",
    "fig.savefig(pdf_path, bbox_inches='tight')\n",
    "print(f\"âœ“ Saved: {plot_name}.png/.pdf\")\n",
    "print(f\"  PNG: {png_path}\")\n",
    "print(f\"  PDF: {pdf_path}\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nâœ“ Visualization complete - {len(available_genes)} marker genes plotted\")\n",
    "print(f\"  Using normalized, log-transformed data from adata_final.X\")\n",
    "print(f\"  Colormap: {colormap_name}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5af3df",
   "metadata": {},
   "source": [
    "### Marker Gene Dotplot\n",
    "Generate a comprehensive dotplot showing marker gene expression across all clusters at a selected resolution. The dotplot uses a dendrogram to organize clusters by similarity and displays both mean expression levels and the percentage of cells expressing each gene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bc156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure inline plotting in Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "# ============================================================\n",
    "# USER CONFIGURATION - DOTPLOT\n",
    "# ============================================================\n",
    "# Select resolution and plot dimensions\n",
    "selected_res = 1.0  # ðŸ‘ˆ Change this to any desired resolution\n",
    "plot_width = 5     # ðŸ‘ˆ Change figure width (in inches)\n",
    "plot_height = 10    # ðŸ‘ˆ Change figure height (in inches)\n",
    "\n",
    "# ============================================================\n",
    "# VERIFY DATA AND LAYERS\n",
    "# ============================================================\n",
    "\n",
    "# Verify clustering column exists\n",
    "cluster_key = f'leiden_r{selected_res}'\n",
    "if cluster_key not in adata_final.obs:\n",
    "    available_leiden = [col for col in adata_final.obs.columns if col.startswith('leiden_r')]\n",
    "    raise ValueError(\n",
    "        f\"Clustering column '{cluster_key}' not found in adata.obs.\\n\"\n",
    "        f\"Available resolutions: {', '.join(available_leiden)}\"\n",
    "    )\n",
    "\n",
    "print(f\"âœ“ Using clustering: {cluster_key}\")\n",
    "n_clusters = len(adata_final.obs[cluster_key].cat.categories)\n",
    "print(f\"  Number of clusters: {n_clusters}\")\n",
    "\n",
    "# Check data normalization status\n",
    "max_val = adata_final.X.max() if hasattr(adata_final.X, 'max') else adata_final.X.data.max()\n",
    "print(f\"\\nadata_final.X max value: {max_val:.2f}\")\n",
    "\n",
    "# Verify normalized data\n",
    "if max_val > 50:\n",
    "    raise ValueError(\n",
    "        f\"adata_final.X appears to contain raw counts (max={max_val:.0f}). \"\n",
    "        \"Expected normalized/log-transformed data.\"\n",
    "    )\n",
    "\n",
    "# Use adata.X for gene expression (normalized, log-transformed)\n",
    "use_layer = None\n",
    "print(\"âœ“ Using adata_final.X for gene expression (normalized, log-transformed)\")\n",
    "\n",
    "# ============================================================\n",
    "# PREPARE GENE LIST\n",
    "# ============================================================\n",
    "\n",
    "# Use genes from marker_genes_dict (already defined above)\n",
    "# Flatten all marker genes into a single list, preserving order\n",
    "genes = []\n",
    "for cell_type, gene_list in marker_genes_dict.items():\n",
    "    genes.extend(gene_list)\n",
    "\n",
    "# Check available genes\n",
    "available_genes = [g for g in genes if g in adata_final.var_names]\n",
    "missing_genes = [g for g in genes if g not in adata_final.var_names]\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"GENE AVAILABILITY FOR DOTPLOT\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"  Total genes in list: {len(genes)}\")\n",
    "print(f\"  Available in dataset: {len(available_genes)}\")\n",
    "print(f\"  Missing from dataset: {len(missing_genes)}\")\n",
    "\n",
    "if missing_genes:\n",
    "    print(f\"\\n  Missing genes: {', '.join(missing_genes)}\")\n",
    "\n",
    "if not available_genes:\n",
    "    raise ValueError('No valid genes for dotplot.')\n",
    "\n",
    "print(f\"{'=' * 60}\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# CREATE CUSTOM GREY-PLASMA COLORMAP\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Get plasma_r colormap\n",
    "plasma_r = plt.cm.plasma_r\n",
    "n_colors = 256\n",
    "plasma_colors = plasma_r(np.linspace(0, 1, n_colors))\n",
    "\n",
    "# Replace first 20% with grey gradient\n",
    "grey_to_plasma_transition = 0.2\n",
    "n_grey_colors = int(n_colors * grey_to_plasma_transition)\n",
    "\n",
    "# Create grey gradient from light grey to first plasma color\n",
    "light_grey = np.array([0.85, 0.85, 0.85, 1.0])\n",
    "transition_color = plasma_colors[n_grey_colors]\n",
    "grey_gradient = np.linspace(light_grey, transition_color, n_grey_colors)\n",
    "\n",
    "# Combine grey gradient with plasma_r\n",
    "custom_colors = np.vstack([grey_gradient, plasma_colors[n_grey_colors:]])\n",
    "dotplot_colormap = LinearSegmentedColormap.from_list('grey_plasma', custom_colors)\n",
    "\n",
    "print('âœ“ Created custom grey-plasma colormap for dotplot')\n",
    "\n",
    "# Configure plot style\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "sns.set_style('white')\n",
    "\n",
    "# ============================================================\n",
    "# COMPUTE DENDROGRAM FOR CURRENT CLUSTERING\n",
    "# ============================================================\n",
    "print(f'\\nâœ“ Computing dendrogram for {cluster_key}...')\n",
    "sc.tl.dendrogram(adata_final, groupby=cluster_key)\n",
    "print('âœ“ Dendrogram computed')\n",
    "\n",
    "# ============================================================\n",
    "# GENERATE DOTPLOT\n",
    "# ============================================================\n",
    "\n",
    "print(f'\\nâœ“ Generating dotplot...')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(plot_width, plot_height), dpi=300)\n",
    "dotplot = sc.pl.dotplot(\n",
    "    adata_final,\n",
    "    var_names=available_genes,\n",
    "    groupby=cluster_key,\n",
    "    layer=use_layer,\n",
    "    dendrogram=True,\n",
    "    ax=ax,\n",
    "    return_fig=True,\n",
    "    dot_max=0.8,\n",
    "    dot_min=0.05,\n",
    "    colorbar_title='Mean expression\\nin group',\n",
    "    size_title='% of cells\\nexpressing gene',\n",
    "    cmap=dotplot_colormap,  # Use custom grey-plasma colormap\n",
    "    swap_axes=True,\n",
    "    var_group_rotation=90\n",
    ")\n",
    "\n",
    "# Make dot borders thinner\n",
    "main_ax = dotplot.get_axes()['mainplot_ax']\n",
    "for collection in main_ax.collections:\n",
    "    collection.set_linewidths(0)  # Remove dot borders for cleaner look\n",
    "\n",
    "# Force straight cluster names with increased font size\n",
    "main_ax.tick_params(axis='x', labelsize=12, rotation=0)\n",
    "for label in main_ax.get_xticklabels():\n",
    "    label.set_rotation(0)\n",
    "    label.set_ha('center')\n",
    "\n",
    "# Ensure ticks are visible on both axes\n",
    "main_ax.tick_params(axis='both', bottom=True, left=True, labelbottom=True, \n",
    "                    labelleft=True, length=4, direction='out')\n",
    "main_ax.spines['bottom'].set_visible(True)\n",
    "main_ax.spines['left'].set_visible(True)\n",
    "\n",
    "plt.suptitle(f'Gene Expression Dotplot (Normalized, r={selected_res})', \n",
    "             y=1.02, fontsize=18, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plots\n",
    "png_path = png_dir / f'{OUTPUT_PREFIX}_marker_dotplot_r{selected_res}.png'\n",
    "pdf_path = pdf_dir / f'{OUTPUT_PREFIX}_marker_dotplot_r{selected_res}.pdf'\n",
    "fig.savefig(png_path, dpi=300, bbox_inches='tight')\n",
    "fig.savefig(pdf_path, bbox_inches='tight')\n",
    "print(f'\\nâœ“ Saved: marker_dotplot_r{selected_res}.png/.pdf')\n",
    "print(f'  PNG: {png_path}')\n",
    "print(f'  PDF: {pdf_path}')\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(f'\\nâœ“ Dotplot complete')\n",
    "print(f'  Resolution: {selected_res}')\n",
    "print(f'  Clusters: {n_clusters}')\n",
    "print(f'  Genes plotted: {len(available_genes)}')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1af098f",
   "metadata": {},
   "source": [
    "### Filter Out Contaminating Cells\n",
    "Remove non-microglia cell clusters based on marker gene expression analysis. After reviewing the clustering and marker gene plots above, specify which clusters represent contaminating cell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8680fd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure inline plotting in Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "# ============================================================\n",
    "# USER CONFIGURATION - CELL FILTERING\n",
    "# ============================================================\n",
    "# Select resolution used for filtering\n",
    "filter_resolution = 1.0  # ðŸ‘ˆ Resolution to use for identifying clusters to remove\n",
    "\n",
    "# Specify clusters to REMOVE (contaminating cells)\n",
    "# Example: clusters_to_remove = ['0', '5', '12']  # Adjust based on your marker gene analysis\n",
    "clusters_to_remove = ['11']  # ðŸ‘ˆ Add cluster numbers to remove (as strings)\n",
    "\n",
    "# NOTE: Leave empty [] to skip filtering (keep all cells)\n",
    "\n",
    "# ============================================================\n",
    "# VERIFY CLUSTERING AND EXECUTE FILTERING\n",
    "# ============================================================\n",
    "\n",
    "if clusters_to_remove:\n",
    "    # Verify clustering column exists\n",
    "    cluster_key = f'leiden_r{filter_resolution}'\n",
    "    if cluster_key not in adata_final.obs:\n",
    "        available_leiden = [col for col in adata_final.obs.columns if col.startswith('leiden_r')]\n",
    "        raise ValueError(\n",
    "            f\"Clustering column '{cluster_key}' not found.\\n\"\n",
    "            f\"Available resolutions: {', '.join(available_leiden)}\"\n",
    "        )\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"CELL FILTERING\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Using clustering: {cluster_key}\")\n",
    "    print(f\"Clusters to REMOVE: {', '.join(clusters_to_remove)}\")\n",
    "    \n",
    "    # Get cell counts before filtering\n",
    "    n_cells_before = adata_final.n_obs\n",
    "    cluster_counts_before = adata_final.obs[cluster_key].value_counts().sort_index()\n",
    "    \n",
    "    print(f\"\\nBefore filtering:\")\n",
    "    print(f\"  Total cells: {n_cells_before:,}\")\n",
    "    print(f\"  Total clusters: {len(cluster_counts_before)}\")\n",
    "    print(f\"\\n  Cluster distribution:\")\n",
    "    for cluster, count in cluster_counts_before.items():\n",
    "        marker = \" âŒ REMOVE\" if cluster in clusters_to_remove else \"\"\n",
    "        print(f\"    Cluster {cluster}: {count:,} cells{marker}\")\n",
    "    \n",
    "    # Perform filtering - keep cells NOT in clusters_to_remove\n",
    "    mask = ~adata_final.obs[cluster_key].isin(clusters_to_remove)\n",
    "    adata_filtered_microglia = adata_final[mask].copy()\n",
    "    \n",
    "    # Get cell counts after filtering\n",
    "    n_cells_after = adata_filtered_microglia.n_obs\n",
    "    n_cells_removed = n_cells_before - n_cells_after\n",
    "    cluster_counts_after = adata_filtered_microglia.obs[cluster_key].value_counts().sort_index()\n",
    "    \n",
    "    print(f\"\\nAfter filtering:\")\n",
    "    print(f\"  Total cells: {n_cells_after:,}\")\n",
    "    print(f\"  Cells removed: {n_cells_removed:,} ({100*n_cells_removed/n_cells_before:.1f}%)\")\n",
    "    print(f\"  Remaining clusters: {len(cluster_counts_after)}\")\n",
    "    print(f\"\\n  Remaining cluster distribution:\")\n",
    "    for cluster, count in cluster_counts_after.items():\n",
    "        print(f\"    Cluster {cluster}: {count:,} cells\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"âœ“ Filtering complete\")\n",
    "    print(\"=\" * 60 + \"\\n\")\n",
    "    \n",
    "else:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"CELL FILTERING\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"â­ï¸  No clusters specified for removal (clusters_to_remove is empty)\")\n",
    "    print(\"   Keeping all cells in adata_final\")\n",
    "    print(\"=\" * 60 + \"\\n\")\n",
    "    \n",
    "    # No filtering - just copy\n",
    "    adata_filtered_microglia = adata_final.copy()\n",
    "\n",
    "# ============================================================\n",
    "# VISUALIZE FILTERED DATA\n",
    "# ============================================================\n",
    "\n",
    "if clusters_to_remove:\n",
    "    print(\"âœ“ Generating confirmation UMAP...\")\n",
    "    \n",
    "    # Configure plot\n",
    "    point_size = 40\n",
    "    \n",
    "    # Create side-by-side comparison\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6), dpi=300)\n",
    "    \n",
    "    # Before filtering (all cells, highlight removed clusters)\n",
    "    sc.pl.umap(adata_final, \n",
    "               color=cluster_key, \n",
    "               ax=axes[0], \n",
    "               show=False,\n",
    "               title=f'Before Filtering (n={adata_final.n_obs:,})',\n",
    "               frameon=False,\n",
    "               size=point_size,\n",
    "               legend_loc='on data')\n",
    "    \n",
    "    # After filtering (only microglia)\n",
    "    sc.pl.umap(adata_filtered_microglia, \n",
    "               color=cluster_key, \n",
    "               ax=axes[1], \n",
    "               show=False,\n",
    "               title=f'After Filtering (n={adata_filtered_microglia.n_obs:,})',\n",
    "               frameon=False,\n",
    "               size=point_size,\n",
    "               legend_loc='on data')\n",
    "    \n",
    "    removed_text = ', '.join(clusters_to_remove)\n",
    "    plt.suptitle(f'Cell Filtering Confirmation (Removed clusters: {removed_text})', \n",
    "                 y=1.02, fontsize=18, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save comparison plot\n",
    "    png_path = png_dir / f'{OUTPUT_PREFIX}_filtering_confirmation.png'\n",
    "    pdf_path = pdf_dir / f'{OUTPUT_PREFIX}_filtering_confirmation.pdf'\n",
    "    fig.savefig(png_path, dpi=300, bbox_inches='tight')\n",
    "    fig.savefig(pdf_path, bbox_inches='tight')\n",
    "    print(f'\\nâœ“ Saved filtering confirmation plot')\n",
    "    print(f'  PNG: {png_path}')\n",
    "    print(f'  PDF: {pdf_path}')\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    print(f'\\nâœ“ Visualization complete')\n",
    "    print('=' * 60)\n",
    "else:\n",
    "    print(\"â­ï¸  Skipping visualization (no filtering performed)\")\n",
    "\n",
    "# ============================================================\n",
    "# VERIFY FILTERED DATA\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FILTERED DATA SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Final cell count: {adata_filtered_microglia.n_obs:,}\")\n",
    "print(f\"Gene count: {adata_filtered_microglia.n_vars:,}\")\n",
    "print(f\"\\nData layers:\")\n",
    "print(f\"  - adata.X: Normalized, log-transformed\")\n",
    "if 'counts' in adata_filtered_microglia.layers:\n",
    "    print(f\"  - adata.layers['counts']: Raw counts (for scVI)\")\n",
    "print(f\"\\nMetadata columns:\")\n",
    "print(f\"  - library: {adata_filtered_microglia.obs['library'].unique()[0]}\")\n",
    "print(f\"  - batch: {adata_filtered_microglia.obs['batch'].unique()[0]}\")\n",
    "print(f\"  - mouse: {adata_filtered_microglia.obs['mouse'].unique()[0]}\")\n",
    "print(f\"  - sex: {adata_filtered_microglia.obs['sex'].unique()[0]}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db540653",
   "metadata": {},
   "source": [
    "### Save Filtered Microglia Data for Integration\n",
    "Prepare the filtered microglia dataset for downstream scVI integration by:\n",
    "1. Restoring raw counts to `adata.X` (from `adata.layers['counts']`)\n",
    "2. Removing preprocessing artifacts (UMAP, PCA, clustering results)\n",
    "3. Preserving essential metadata (library, batch, sex, mouse)\n",
    "4. Saving a clean dataset ready for integration with other samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ef0508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PREPARE FILTERED DATA FOR INTEGRATION\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PREPARING FILTERED DATA FOR INTEGRATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create a copy for final save\n",
    "adata_microglia_clean = adata_filtered_microglia.copy()\n",
    "\n",
    "# ============================================================\n",
    "# RESTORE RAW COUNTS TO adata.X\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n1. Restoring raw counts to adata.X...\")\n",
    "\n",
    "if 'counts' in adata_microglia_clean.layers:\n",
    "    # Restore raw counts from layer\n",
    "    adata_microglia_clean.X = adata_microglia_clean.layers['counts'].copy()\n",
    "    print(f\"   âœ“ Restored raw counts from adata.layers['counts']\")\n",
    "    \n",
    "    # Verify raw counts\n",
    "    max_val = adata_microglia_clean.X.max() if hasattr(adata_microglia_clean.X, 'max') else adata_microglia_clean.X.data.max()\n",
    "    print(f\"   âœ“ adata.X max value: {max_val:.0f} (raw counts)\")\n",
    "    \n",
    "    if max_val < 50:\n",
    "        print(f\"   âš ï¸  Warning: Max value seems low for raw counts. Please verify.\")\n",
    "else:\n",
    "    raise ValueError(\"adata.layers['counts'] not found. Cannot restore raw counts!\")\n",
    "\n",
    "# ============================================================\n",
    "# REMOVE ALL LAYERS (raw counts now in adata.X)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n2. Removing all layers...\")\n",
    "\n",
    "layer_names = list(adata_microglia_clean.layers.keys())\n",
    "for layer_name in layer_names:\n",
    "    del adata_microglia_clean.layers[layer_name]\n",
    "    \n",
    "if layer_names:\n",
    "    print(f\"   âœ“ Removed layers: {', '.join(layer_names)}\")\n",
    "else:\n",
    "    print(f\"   âœ“ No layers found\")\n",
    "\n",
    "# ============================================================\n",
    "# REMOVE ALL OBSM (dimensionality reduction, etc.)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n3. Removing all obsm entries...\")\n",
    "\n",
    "obsm_keys = list(adata_microglia_clean.obsm.keys())\n",
    "for key in obsm_keys:\n",
    "    del adata_microglia_clean.obsm[key]\n",
    "    \n",
    "if obsm_keys:\n",
    "    print(f\"   âœ“ Removed obsm entries: {', '.join(obsm_keys)}\")\n",
    "else:\n",
    "    print(f\"   âœ“ No obsm entries found\")\n",
    "\n",
    "# ============================================================\n",
    "# REMOVE ALL VARM (PCA loadings, etc.)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n4. Removing all varm entries...\")\n",
    "\n",
    "varm_keys = list(adata_microglia_clean.varm.keys())\n",
    "for key in varm_keys:\n",
    "    del adata_microglia_clean.varm[key]\n",
    "    \n",
    "if varm_keys:\n",
    "    print(f\"   âœ“ Removed varm entries: {', '.join(varm_keys)}\")\n",
    "else:\n",
    "    print(f\"   âœ“ No varm entries found\")\n",
    "\n",
    "# ============================================================\n",
    "# REMOVE CLUSTERING AND HVG FROM OBS/VAR\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n5. Removing clustering and HVG annotations...\")\n",
    "\n",
    "artifacts_removed = []\n",
    "\n",
    "# Remove clustering columns from obs\n",
    "leiden_cols = [col for col in adata_microglia_clean.obs.columns if col.startswith('leiden_r')]\n",
    "for col in leiden_cols:\n",
    "    del adata_microglia_clean.obs[col]\n",
    "if leiden_cols:\n",
    "    artifacts_removed.append(f'{len(leiden_cols)} leiden columns from obs')\n",
    "\n",
    "# Remove HVG-related columns from var\n",
    "hvg_cols = ['highly_variable', 'means', 'dispersions', 'dispersions_norm', \n",
    "            'highly_variable_rank', 'highly_variable_nbatches']\n",
    "for col in hvg_cols:\n",
    "    if col in adata_microglia_clean.var.columns:\n",
    "        del adata_microglia_clean.var[col]\n",
    "        artifacts_removed.append(f'{col} from var')\n",
    "\n",
    "if artifacts_removed:\n",
    "    print(f\"   âœ“ Removed: {', '.join(artifacts_removed)}\")\n",
    "else:\n",
    "    print(f\"   âœ“ No clustering/HVG columns found\")\n",
    "\n",
    "# ============================================================\n",
    "# CLEAN UP UNS (keep only essential metadata)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n6. Cleaning uns dictionary...\")\n",
    "\n",
    "# Keep only essential uns keys (if any)\n",
    "essential_uns = []  # Add any essential keys here if needed\n",
    "\n",
    "uns_keys_to_remove = [key for key in adata_microglia_clean.uns.keys() \n",
    "                       if key not in essential_uns]\n",
    "\n",
    "for key in uns_keys_to_remove:\n",
    "    del adata_microglia_clean.uns[key]\n",
    "\n",
    "if uns_keys_to_remove:\n",
    "    print(f\"   âœ“ Removed {len(uns_keys_to_remove)} uns entries: {', '.join(uns_keys_to_remove)}\")\n",
    "else:\n",
    "    print(f\"   âœ“ No uns entries to remove\")\n",
    "\n",
    "# ============================================================\n",
    "# REMOVE OBSP AND VARP (neighbor graphs, etc.)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n7. Removing obsp and varp entries...\")\n",
    "\n",
    "# Remove obsp (neighbor connectivities, distances)\n",
    "obsp_keys = list(adata_microglia_clean.obsp.keys())\n",
    "for key in obsp_keys:\n",
    "    del adata_microglia_clean.obsp[key]\n",
    "if obsp_keys:\n",
    "    print(f\"   âœ“ Removed obsp entries: {', '.join(obsp_keys)}\")\n",
    "else:\n",
    "    print(f\"   âœ“ No obsp entries found\")\n",
    "\n",
    "# Remove varp\n",
    "varp_keys = list(adata_microglia_clean.varp.keys())\n",
    "for key in varp_keys:\n",
    "    del adata_microglia_clean.varp[key]\n",
    "if varp_keys:\n",
    "    print(f\"   âœ“ Removed varp entries: {', '.join(varp_keys)}\")\n",
    "else:\n",
    "    print(f\"   âœ“ No varp entries found\")\n",
    "\n",
    "# ============================================================\n",
    "# VERIFY ESSENTIAL METADATA\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n8. Verifying essential metadata columns...\")\n",
    "\n",
    "required_metadata = ['library', 'batch', 'sex', 'mouse']\n",
    "missing_metadata = [col for col in required_metadata if col not in adata_microglia_clean.obs.columns]\n",
    "\n",
    "if missing_metadata:\n",
    "    raise ValueError(f\"Missing required metadata columns: {', '.join(missing_metadata)}\")\n",
    "\n",
    "print(f\"   âœ“ All required metadata columns present:\")\n",
    "for col in required_metadata:\n",
    "    unique_vals = adata_microglia_clean.obs[col].unique()\n",
    "    if len(unique_vals) == 1:\n",
    "        print(f\"     - {col}: {unique_vals[0]}\")\n",
    "    else:\n",
    "        print(f\"     - {col}: {len(unique_vals)} unique values\")\n",
    "\n",
    "# ============================================================\n",
    "# VERIFY QC METRICS ARE PRESERVED\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n9. Verifying QC metrics...\")\n",
    "\n",
    "qc_columns = ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', \n",
    "              'pct_counts_ribo', 'pct_counts_hb']\n",
    "present_qc = [col for col in qc_columns if col in adata_microglia_clean.obs.columns]\n",
    "\n",
    "if present_qc:\n",
    "    print(f\"   âœ“ QC metrics preserved: {', '.join(present_qc)}\")\n",
    "else:\n",
    "    print(f\"   âš ï¸  Warning: No QC metrics found in obs\")\n",
    "\n",
    "# ============================================================\n",
    "# VERIFY CELL CYCLE SCORES ARE PRESERVED\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n10. Verifying cell cycle scores...\")\n",
    "\n",
    "cc_columns = ['S_score', 'G2M_score', 'phase']\n",
    "present_cc = [col for col in cc_columns if col in adata_microglia_clean.obs.columns]\n",
    "\n",
    "if present_cc:\n",
    "    print(f\"   âœ“ Cell cycle scores preserved: {', '.join(present_cc)}\")\n",
    "else:\n",
    "    print(f\"   âš ï¸  Warning: No cell cycle scores found in obs\")\n",
    "\n",
    "# ============================================================\n",
    "# FINAL DATA SUMMARY\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CLEAN DATA SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Cells: {adata_microglia_clean.n_obs:,}\")\n",
    "print(f\"Genes: {adata_microglia_clean.n_vars:,}\")\n",
    "\n",
    "print(f\"\\nadata.X:\")\n",
    "print(f\"  Type: {type(adata_microglia_clean.X).__name__}\")\n",
    "print(f\"  Shape: {adata_microglia_clean.X.shape}\")\n",
    "print(f\"  Data: Raw counts ONLY (for scVI integration)\")\n",
    "\n",
    "print(f\"\\nLayers: {list(adata_microglia_clean.layers.keys())} (should be empty)\")\n",
    "print(f\"Obsm keys: {list(adata_microglia_clean.obsm.keys())} (should be empty)\")\n",
    "print(f\"Varm keys: {list(adata_microglia_clean.varm.keys())} (should be empty)\")\n",
    "print(f\"Obsp keys: {list(adata_microglia_clean.obsp.keys())} (should be empty)\")\n",
    "print(f\"Varp keys: {list(adata_microglia_clean.varp.keys())} (should be empty)\")\n",
    "print(f\"Uns keys: {list(adata_microglia_clean.uns.keys())} (should be minimal/empty)\")\n",
    "\n",
    "print(f\"\\nMetadata (obs) columns: {len(adata_microglia_clean.obs.columns)}\")\n",
    "print(f\"  Key columns: {', '.join(required_metadata)}\")\n",
    "print(f\"  All obs columns: {list(adata_microglia_clean.obs.columns)}\")\n",
    "\n",
    "print(f\"\\nGene metadata (var) columns: {len(adata_microglia_clean.var.columns)}\")\n",
    "print(f\"  All var columns: {list(adata_microglia_clean.var.columns)}\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================\n",
    "# SAVE CLEAN MICROGLIA DATA\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAVING CLEAN MICROGLIA DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Generate filename\n",
    "output_filename = f\"{OUTPUT_PREFIX}_QC_filtered_microglia_only.h5ad\"\n",
    "output_path = results_dir / output_filename\n",
    "\n",
    "# Save the data\n",
    "adata_microglia_clean.write(output_path)\n",
    "\n",
    "print(f\"\\nâœ“ Saved filtered microglia data:\")\n",
    "print(f\"  File: {output_path}\")\n",
    "print(f\"  Cells: {adata_microglia_clean.n_obs:,}\")\n",
    "print(f\"  Genes: {adata_microglia_clean.n_vars:,}\")\n",
    "print(f\"  Data: Raw counts ONLY in adata.X\")\n",
    "print(f\"  Ready for: scVI integration with other samples\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ“ DATA PREPARATION COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================\n",
    "# QUICK VERIFICATION CHECK\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nðŸ“‹ Quick Verification Checklist:\")\n",
    "print(f\"  âœ“ Raw counts in adata.X\")\n",
    "print(f\"  âœ“ All layers removed\")\n",
    "print(f\"  âœ“ No UMAP/PCA (obsm empty)\")\n",
    "print(f\"  âœ“ No neighbor graphs (obsp empty)\")\n",
    "print(f\"  âœ“ No HVG annotations\")\n",
    "print(f\"  âœ“ No clustering results\")\n",
    "print(f\"  âœ“ Metadata columns preserved: {', '.join(required_metadata)}\")\n",
    "print(f\"  âœ“ QC metrics preserved\")\n",
    "print(f\"  âœ“ Cell cycle scores preserved\")\n",
    "print(f\"  âœ“ Ready for integration\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Next Steps:\")\n",
    "print(\"  1. Process other samples using this same pipeline\")\n",
    "print(\"  2. Load all filtered samples\")\n",
    "print(\"  3. Concatenate datasets\")\n",
    "print(\"  4. Run scVI integration\")\n",
    "print(\"  5. Perform downstream analysis\")\n",
    "\n",
    "print(\"\\nðŸ’¾ File size should be minimal (only raw counts + metadata)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10dfc3d",
   "metadata": {},
   "source": [
    "### Session Info and Outputs\n",
    "Record environment, key package versions, saved outputs, and timestamp.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d96eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session info\n",
    "venv_name = \"scRNAseq-scVI\"  # adjust if needed\n",
    "print(f\"Venv: {venv_name}\")\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(\"Packages:\")\n",
    "for pkg in ['anndata', 'scanpy', 'scvi-tools', 'mudata', 'muon']:\n",
    "    print(f\"{pkg}: {pkg_resources.get_distribution(pkg).version}\")\n",
    "print(f\"Completed: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d5052f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scRNAseq-scVI Env",
   "language": "python",
   "name": "scrnaseq-scvi_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
