{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Single-Cell RNA-seq Analysis with Scanpy & scvi-tools\n",
    "\n",
    "This notebook provides a comprehensive workflow for analyzing single-cell RNA-seq data using Scanpy and scvi-tools. The pipeline loads multiple .h5ad files, concatenates them, and applies scVI for batch correction and covariate adjustment.\n",
    "\n",
    "**Key Features**:\n",
    "- Automatic loading and concatenation of all .h5ad files from inputs folder\n",
    "- Batch correction using scVI (batch_key='batch')\n",
    "- Categorical covariate: 'sample'\n",
    "- Continuous covariates: Cell cycle scores ('S.Phase', 'G2M.Phase')\n",
    "- Support for RNA and HTO data\n",
    "- Raw data preservation for reproducibility\n",
    "- Automated visualization generation\n",
    "- Generic design for reuse across different datasets\n",
    "\n",
    "**Outputs**:\n",
    "- Integrated AnnData objects (HVG subset and full genes)\n",
    "- Training loss visualizations\n",
    "- Comprehensive data structure documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "**Purpose**: Import required libraries and configure analysis parameters. Set up directory structure and plotting preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURATION PARAMETERS ===\n",
    "# Modify these parameters for your specific dataset\n",
    "\n",
    "# Directory configuration\n",
    "INPUT_DIR = 'inputs'  # Directory containing input .h5ad files\n",
    "OUTPUT_DIR = 'outputs'  # Directory for output files\n",
    "\n",
    "# Analysis parameters\n",
    "N_TOP_GENES = 3000  # Number of highly variable genes to select\n",
    "MAX_EPOCHS = 400  # Maximum training epochs for totalVI\n",
    "BATCH_SIZE = 256  # Batch size for training (adjust based on available memory)\n",
    "EARLY_STOPPING_PATIENCE = 20  # Epochs to wait before early stopping\n",
    "\n",
    "# HTO features (will be extracted from data)\n",
    "HTO_FEATURES = None\n",
    "\n",
    "# === JUPYTER NOTEBOOK CONFIGURATION ===\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# === LIBRARY IMPORTS ===\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scanpy as sc\n",
    "import scvi\n",
    "import mudata as md\n",
    "import torch\n",
    "import muon\n",
    "import sys, pkg_resources, datetime\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# === DIRECTORY SETUP ===\n",
    "input_dir = Path(INPUT_DIR)\n",
    "output_dir = Path(OUTPUT_DIR)\n",
    "(output_dir / \"png\").mkdir(parents=True, exist_ok=True)\n",
    "(output_dir / \"pdf\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === SCANPY CONFIGURATION ===\n",
    "sc.set_figure_params(dpi=300, figsize=(6, 4))\n",
    "\n",
    "# === PLOTTING UTILITIES ===\n",
    "def configure_plot_style():\n",
    "    \"\"\"Configure matplotlib and seaborn styles for consistent plotting.\"\"\"\n",
    "    plt.rcParams['figure.dpi'] = 100\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    sns.set_style('white')\n",
    "\n",
    "def show_inline_plot(fig=None):\n",
    "    \"\"\"Display plot inline in Jupyter notebook.\"\"\"\n",
    "    plt.tight_layout()\n",
    "    display(HTML('<div style=\"display: flex; justify-content: center;\">'))\n",
    "    if fig is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        display(fig)\n",
    "    display(HTML('</div>'))\n",
    "\n",
    "def save_plot(name):\n",
    "    \"\"\"Save current plot as both PNG and PDF formats.\"\"\"\n",
    "    plt.tight_layout()\n",
    "    for fmt in ['png', 'pdf']:\n",
    "        path = output_dir / fmt / f\"{name}.{fmt}\"\n",
    "        if fmt == 'png':\n",
    "            plt.savefig(path, dpi=300, bbox_inches='tight')\n",
    "        else:\n",
    "            plt.savefig(path, bbox_inches='tight')\n",
    "    print(f\"Saved: {name}.png/.pdf\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "**Purpose**: Load single-cell datasets from input directory and add batch metadata for downstream integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_merge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOAD SPECIFIC .H5AD FILES ===\n",
    "print(\"=== Loading Individual Datasets ===\\n\")\n",
    "\n",
    "# Define file names and their corresponding groups\n",
    "files_to_load = [\n",
    "    ('PBS-CFA_QC_filtered_microglia_only.h5ad', 'PBS-CFA'),\n",
    "    ('PEP15-CFA_QC_filtered_microglia_only.h5ad', 'PEP15-CFA')\n",
    "]\n",
    "\n",
    "# Load each file as a separate adata object\n",
    "\n",
    "adata1 = sc.read_h5ad(input_dir / files_to_load[0][0])\n",
    "print(f\"adata1 (PBS-CFA): {adata1.shape[0]:,} cells, {adata1.shape[1]:,} genes\")\n",
    "\n",
    "adata2 = sc.read_h5ad(input_dir / files_to_load[1][0])\n",
    "print(f\"adata2 (PEP15-CFA): {adata2.shape[0]:,} cells, {adata2.shape[1]:,} genes\")\n",
    "\n",
    "# === CONCATENATE ALL DATASETS ===\n",
    "print(f\"\\n=== Joining Datasets ===\")\n",
    "adata_list = [adata1, adata2]\n",
    "adata = ad.concat(adata_list, join='outer', merge='same', index_unique='_')\n",
    "\n",
    "print(f\"Total cells: {adata.shape[0]:,}\")\n",
    "print(f\"Total genes: {adata.shape[1]:,}\")\n",
    "\n",
    "# === CREATE GROUP COLUMN ===\n",
    "print(f\"\\n=== Creating Group Column ===\")\n",
    "\n",
    "# Create a mapping from library name to group\n",
    "# First, we need to identify which cells belong to which original dataset\n",
    "# The concatenation adds suffixes to the cell names, so we can use the batch indices\n",
    "\n",
    "# Get the library/mouse names from the original datasets\n",
    "if 'library' in adata.obs.columns:\n",
    "    # Use the library column to determine the group\n",
    "    library_to_group = {}\n",
    "    \n",
    "    # Check unique library values to determine mapping\n",
    "    for idx, (filename, group) in enumerate(files_to_load):\n",
    "        # Get the library name from the original adata object\n",
    "        temp_lib = adata_list[idx].obs['library'].unique()[0] if 'library' in adata_list[idx].obs.columns else f\"unknown_{idx}\"\n",
    "        library_to_group[temp_lib] = group\n",
    "    \n",
    "    # Create the group column based on library\n",
    "    adata.obs['group'] = adata.obs['library'].map(library_to_group)\n",
    "    \n",
    "elif 'mouse' in adata.obs.columns:\n",
    "    # Alternative: use mouse column\n",
    "    mouse_to_group = {}\n",
    "    for idx, (filename, group) in enumerate(files_to_load):\n",
    "        temp_mouse = adata_list[idx].obs['mouse'].unique()[0] if 'mouse' in adata_list[idx].obs.columns else f\"unknown_{idx}\"\n",
    "        mouse_to_group[temp_mouse] = group\n",
    "    \n",
    "    adata.obs['group'] = adata.obs['mouse'].map(mouse_to_group)\n",
    "else:\n",
    "    # If no library or mouse column, assign based on batch index\n",
    "    # Create group column based on which dataset the cells came from\n",
    "    group_list = []\n",
    "    start_idx = 0\n",
    "    for idx, temp_adata in enumerate(adata_list):\n",
    "        n_cells = temp_adata.shape[0]\n",
    "        group_list.extend([files_to_load[idx][1]] * n_cells)\n",
    "        start_idx += n_cells\n",
    "    \n",
    "    adata.obs['group'] = group_list\n",
    "\n",
    "print(f\"Group assignments:\")\n",
    "print(adata.obs['group'].value_counts())\n",
    "\n",
    "# Display metadata summary\n",
    "print(f\"\\n=== Metadata Summary ===\")\n",
    "if 'batch' in adata.obs.columns:\n",
    "    print(f\"\\nBatch distribution:\")\n",
    "    print(adata.obs['batch'].value_counts())\n",
    "\n",
    "if 'library' in adata.obs.columns:\n",
    "    print(f\"\\nLibrary distribution:\")\n",
    "    print(adata.obs['library'].value_counts())\n",
    "\n",
    "if 'mouse' in adata.obs.columns:\n",
    "    print(f\"\\nMouse distribution:\")\n",
    "    print(adata.obs['mouse'].value_counts())\n",
    "\n",
    "if 'sex' in adata.obs.columns:\n",
    "    print(f\"\\nSex distribution:\")\n",
    "    print(adata.obs['sex'].value_counts())\n",
    "\n",
    "print(\"\\n✅ Data loading and group assignment complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210c62c4",
   "metadata": {},
   "source": [
    "## Remove Outlier Sample\n",
    "\n",
    "**Purpose**: Remove cells from the outlier sample 'HTO_PBS-4' from the mouse column. This sample showed abnormal characteristics and should be excluded from downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed70c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === REMOVE OUTLIER SAMPLE ===\n",
    "print(\"\\n=== Removing Outlier Sample ===\")\n",
    "\n",
    "# Check if 'mouse' column exists\n",
    "if 'mouse' in adata.obs.columns:\n",
    "    # Count cells before filtering\n",
    "    n_cells_before = adata.shape[0]\n",
    "    \n",
    "    # Check how many cells have HTO_PBS-4\n",
    "    n_pbs4_cells = (adata.obs['mouse'] == 'HTO_PBS-4').sum()\n",
    "    print(f\"\\nCells with HTO_PBS-4: {n_pbs4_cells:,}\")\n",
    "    \n",
    "    # Filter out HTO_PBS-4 cells\n",
    "    adata = adata[adata.obs['mouse'] != 'HTO_PBS-4'].copy()\n",
    "    \n",
    "    # Count cells after filtering\n",
    "    n_cells_after = adata.shape[0]\n",
    "    print(f\"\\nCells before filtering: {n_cells_before:,}\")\n",
    "    print(f\"Cells after filtering: {n_cells_after:,}\")\n",
    "    print(f\"Cells removed: {n_cells_before - n_cells_after:,}\")\n",
    "    \n",
    "    # Display updated metadata summary\n",
    "    print(f\"\\n=== Updated Metadata Summary ===\")\n",
    "    \n",
    "    if 'group' in adata.obs.columns:\n",
    "        print(f\"\\nGroup distribution:\")\n",
    "        print(adata.obs['group'].value_counts())\n",
    "    \n",
    "    if 'batch' in adata.obs.columns:\n",
    "        print(f\"\\nBatch distribution:\")\n",
    "        print(adata.obs['batch'].value_counts())\n",
    "    \n",
    "    if 'library' in adata.obs.columns:\n",
    "        print(f\"\\nLibrary distribution:\")\n",
    "        print(adata.obs['library'].value_counts())\n",
    "    \n",
    "    print(f\"\\nMouse distribution:\")\n",
    "    print(adata.obs['mouse'].value_counts())\n",
    "    \n",
    "    print(\"\\n✅ Outlier sample removed!\")\n",
    "else:\n",
    "    print(\"⚠️ Warning: 'mouse' column not found in adata.obs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c45aa4",
   "metadata": {},
   "source": [
    "## Set Categorical Order for Metadata Columns\n",
    "\n",
    "**Purpose**: Define the display order for categorical columns (library, batch, mouse_ID) to ensure consistent visualization and analysis ordering throughout the workflow.\n",
    "\n",
    "**Why this matters**: By setting ordered categories, plots and tables will display samples in a logical, consistent order rather than alphabetically or randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a291c8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SET CATEGORICAL ORDER FOR KEY COLUMNS ===\n",
    "print(\"\\n--- Setting Categorical Order ---\")\n",
    "\n",
    "# Set group order\n",
    "group_order = ['PBS-CFA', 'PEP15-CFA']\n",
    "if 'group' in adata.obs.columns:\n",
    "    adata.obs['group'] = pd.Categorical(\n",
    "        adata.obs['group'],\n",
    "        categories=group_order,\n",
    "        ordered=True\n",
    "    )\n",
    "    print(f\"✅ Group order set: {group_order}\")\n",
    "\n",
    "# Set library order (explicit)\n",
    "library_order = ['PBS-CFA', 'PEP15-CFA']\n",
    "if 'library' in adata.obs.columns:\n",
    "    adata.obs['library'] = pd.Categorical(\n",
    "        adata.obs['library'],\n",
    "        categories=library_order,\n",
    "        ordered=True\n",
    "    )\n",
    "    print(f\"✅ Library order set: {library_order}\")\n",
    "\n",
    "# Set batch order (explicit)\n",
    "batch_order = ['Mistri']\n",
    "if 'batch' in adata.obs.columns:\n",
    "    adata.obs['batch'] = pd.Categorical(\n",
    "        adata.obs['batch'],\n",
    "        categories=batch_order,\n",
    "        ordered=True\n",
    "    )\n",
    "    print(f\"✅ Batch order set: {batch_order}\")\n",
    "\n",
    "# Set mouse order (explicit)\n",
    "mouse_order = [\n",
    "    'HTO_PBS-1', 'HTO_PBS-2', 'HTO_PBS-3', 'HTO_PBS-5', 'HTO_PBS-6',  # PBS mice\n",
    "    'HTO_PEP15-1', 'HTO_PEP15-2', 'HTO_PEP15-3', 'HTO_PEP15-4', 'HTO_PEP15-5', 'HTO_PEP15-6'  # PEP15 mice\n",
    "    \n",
    "]\n",
    "if 'mouse' in adata.obs.columns:\n",
    "    adata.obs['mouse'] = pd.Categorical(\n",
    "        adata.obs['mouse'],\n",
    "        categories=mouse_order,\n",
    "        ordered=True\n",
    "    )\n",
    "    print(f\"✅ Mouse order set: {mouse_order}\")\n",
    "\n",
    "# Set sex order (explicit)\n",
    "sex_order = ['female']\n",
    "if 'sex' in adata.obs.columns:\n",
    "    adata.obs['sex'] = pd.Categorical(\n",
    "        adata.obs['sex'],\n",
    "        categories=sex_order,\n",
    "        ordered=True\n",
    "    )\n",
    "    print(f\"✅ Sex order set: {sex_order}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38452690",
   "metadata": {},
   "source": [
    "## Dataset Structure Inspection\n",
    "\n",
    "**Purpose**: Examine dataset structure to verify data types, modalities, and metadata before integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ac22d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DATASET STRUCTURE INSPECTION ===\n",
    "# Examine the dataset to understand data structure\n",
    "print(f\"Inspecting dataset structure...\")\n",
    "\n",
    "# === RNA DATA INSPECTION ===\n",
    "print(\"\\n--- RNA Expression Data ---\")\n",
    "print(f\"Type: {type(adata.X)}\")\n",
    "print(f\"Shape: {adata.X.shape}\")\n",
    "if hasattr(adata.X, 'nnz'):\n",
    "    sparsity = (1 - adata.X.nnz / (adata.X.shape[0] * adata.X.shape[1])) * 100\n",
    "    print(f\"Sparsity: {sparsity:.2f}%\")\n",
    "\n",
    "# === MULTIMODAL DATA INSPECTION ===\n",
    "print(\"\\n--- Additional Modalities ---\")\n",
    "for modality in ['HTO', 'ADT', 'protein']:\n",
    "    if modality in adata.obsm:\n",
    "        print(f\"{modality}: {adata.obsm[modality].shape}\")\n",
    "        if f'{modality}_features' in adata.uns:\n",
    "            print(f\"  Features: {adata.uns[f'{modality}_features']}\")\n",
    "    else:\n",
    "        print(f\"{modality}: Not found\")\n",
    "\n",
    "# === METADATA INSPECTION ===\n",
    "print(\"\\n--- Metadata Structure ---\")\n",
    "print(f\"Metadata shape: {adata.obs.shape}\")\n",
    "print(f\"Metadata columns: {len(adata.obs.columns)}\")\n",
    "\n",
    "# Show sample metadata columns\n",
    "print(\"\\nSample metadata columns:\")\n",
    "sample_cols = adata.obs.columns[:10].tolist()\n",
    "print(sample_cols)\n",
    "\n",
    "# === CATEGORICAL VARIABLES INSPECTION ===\n",
    "print(\"\\n--- Categorical Variables ---\")\n",
    "categorical_cols = adata.obs.select_dtypes(include=['category', 'object']).columns\n",
    "for col in categorical_cols[:5]:  # Show first 5 categorical columns\n",
    "    unique_vals = adata.obs[col].unique()\n",
    "    print(f\"{col}: {len(unique_vals)} unique values\")\n",
    "    if len(unique_vals) <= 10:\n",
    "        print(f\"  Values: {unique_vals}\")\n",
    "    else:\n",
    "        print(f\"  Sample values: {unique_vals[:5]}...\")\n",
    "\n",
    "# === CHECK FOR REQUIRED QC COLUMNS ===\n",
    "required_columns = ['pct_counts_mt', 'S_score', 'G2M_score']\n",
    "print(\"\\n--- Required QC Columns Check ---\")\n",
    "for col in required_columns:\n",
    "    if col in adata.obs.columns:\n",
    "        print(f\"✅ {col}: Present\")\n",
    "    else:\n",
    "        print(f\"❌ {col}: Missing - will need to compute\")\n",
    "\n",
    "# === CHECK FOR KEY METADATA COLUMNS ===\n",
    "print(\"\\n--- Key Metadata Columns ---\")\n",
    "for col in ['batch', 'library', 'mouse']:\n",
    "    if col in adata.obs.columns:\n",
    "        unique_count = adata.obs[col].nunique()\n",
    "        print(f\"✅ {col}: {unique_count} unique values\")\n",
    "        if unique_count <= 20:\n",
    "            print(f\"  Values: {adata.obs[col].value_counts().to_dict()}\")\n",
    "    else:\n",
    "        print(f\"❌ {col}: Not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e231ee",
   "metadata": {},
   "source": [
    "## Data Preparation and Metadata Verification\n",
    "\n",
    "**Purpose**: Verify cell identifiers are unique and ensure all required metadata columns (batch, sample, cell cycle scores) are present for downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38a1583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MAKE CELL IDENTIFIERS UNIQUE ===\n",
    "adata.obs_names_make_unique()\n",
    "assert adata.obs_names.is_unique, \"Cell identifiers are not unique!\"\n",
    "print(f\"✅ Cell identifiers are unique: {adata.shape[0]:,} cells\")\n",
    "\n",
    "# === VERIFY REQUIRED COLUMNS FOR SCVI ===\n",
    "print(\"\\n--- Verifying Required Columns ---\")\n",
    "\n",
    "# Check for group column\n",
    "if 'group' in adata.obs.columns:\n",
    "    print(f\"✅ 'group' column: {adata.obs['group'].nunique()} unique groups\")\n",
    "    print(f\"   Groups: {sorted(adata.obs['group'].unique().tolist())}\")\n",
    "    print(f\"   Group distribution:\")\n",
    "    for group in sorted(adata.obs['group'].unique()):\n",
    "        count = (adata.obs['group'] == group).sum()\n",
    "        print(f\"     - {group}: {count:,} cells\")\n",
    "else:\n",
    "    print(\"❌ 'group' column not found\")\n",
    "\n",
    "# Check for batch column\n",
    "if 'batch' in adata.obs.columns:\n",
    "    print(f\"\\n✅ 'batch' column: {adata.obs['batch'].nunique()} unique batches\")\n",
    "    print(f\"   Batches: {sorted(adata.obs['batch'].unique().tolist())}\")\n",
    "else:\n",
    "    print(\"\\n⚠️  'batch' column not found - will use 'library' as batch key for scVI\")\n",
    "\n",
    "# Check for library column\n",
    "if 'library' in adata.obs.columns:\n",
    "    print(f\"\\n✅ 'library' column: {adata.obs['library'].nunique()} unique libraries\")\n",
    "    print(f\"   Libraries: {sorted(adata.obs['library'].unique().tolist())}\")\n",
    "else:\n",
    "    print(\"\\n❌ 'library' column not found\")\n",
    "\n",
    "# Check for mouse column\n",
    "if 'mouse' in adata.obs.columns:\n",
    "    print(f\"\\n✅ 'mouse' column: {adata.obs['mouse'].nunique()} unique mice\")\n",
    "else:\n",
    "    print(\"\\n⚠️  'mouse' column not found\")\n",
    "\n",
    "# Check for cell cycle scores\n",
    "if 'S_score' in adata.obs.columns:\n",
    "    print(f\"\\n✅ 'S_score' column found\")\n",
    "else:\n",
    "    print(\"\\n❌ 'S_score' column not found\")\n",
    "\n",
    "if 'G2M_score' in adata.obs.columns:\n",
    "    print(f\"✅ 'G2M_score' column found\")\n",
    "else:\n",
    "    print(\"❌ 'G2M_score' column not found\")\n",
    "\n",
    "# === SUMMARY ===\n",
    "print(f\"\\n=== Summary ===\")\n",
    "print(f\"✅ Ready for scVI modeling with {adata.shape[0]:,} cells and {adata.shape[1]:,} genes\")\n",
    "\n",
    "# Determine batch key for scVI\n",
    "batch_key = 'batch' if 'batch' in adata.obs.columns else 'library'\n",
    "print(f\"✅ Batch correction will use '{batch_key}' column\")\n",
    "\n",
    "# Determine categorical covariate\n",
    "if 'library' in adata.obs.columns and batch_key != 'library':\n",
    "    print(f\"✅ Categorical covariate: 'library'\")\n",
    "elif 'group' in adata.obs.columns:\n",
    "    print(f\"✅ Categorical covariate: 'group'\")\n",
    "\n",
    "# Check for continuous covariates\n",
    "if 'S_score' in adata.obs.columns and 'G2M_score' in adata.obs.columns:\n",
    "    print(f\"✅ Continuous covariates: 'S_score' and 'G2M_score'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456fc1db",
   "metadata": {},
   "source": [
    "## Cell Count Visualization\n",
    "\n",
    "**Purpose**: Generate publication-quality barplot showing cell counts per batch/sample for quality assessment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3292fd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL COUNT VISUALIZATION ===\n",
    "print(\"=== Cell Count Visualization ===\\n\")\n",
    "\n",
    "# Configure plot style\n",
    "configure_plot_style()\n",
    "\n",
    "# === PLOT: GROUP COUNTS ===\n",
    "if 'group' in adata.obs.columns:\n",
    "    group_counts = adata.obs['group'].value_counts()\n",
    "    \n",
    "    print(f\"--- Group cell counts ---\")\n",
    "    print(group_counts)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Professional color palette\n",
    "    bar_color = '#2E86AB'  # Professional blue color\n",
    "    \n",
    "    # Create group barplot with the ordered categories\n",
    "    ax1 = sns.countplot(data=adata.obs, x='group', color=bar_color, \n",
    "                       order=adata.obs['group'].cat.categories if hasattr(adata.obs['group'], 'cat') else None)\n",
    "    \n",
    "    # Customize plot appearance\n",
    "    plt.title('Cell Counts per Group', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Group', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Number of Cells', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Rotate x-axis labels for better readability\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "    \n",
    "    # Add grid for better readability\n",
    "    plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Annotate bars with exact cell counts\n",
    "    for p in ax1.patches:\n",
    "        count = int(p.get_height())\n",
    "        ax1.annotate(f'{count:,}', \n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                    ha='center', va='bottom', fontsize=10, fontweight='bold',\n",
    "                    color='black', xytext=(0, 8), textcoords='offset points')\n",
    "    \n",
    "    # Adjust layout and display plot inline\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Create a new figure for saving\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax_save = sns.countplot(data=adata.obs, x='group', color=bar_color, \n",
    "                           order=adata.obs['group'].cat.categories if hasattr(adata.obs['group'], 'cat') else None)\n",
    "    plt.title('Cell Counts per Group', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Group', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Number of Cells', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "    plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    for p in ax_save.patches:\n",
    "        count = int(p.get_height())\n",
    "        ax_save.annotate(f'{count:,}', \n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                    ha='center', va='bottom', fontsize=10, fontweight='bold',\n",
    "                    color='black', xytext=(0, 8), textcoords='offset points')\n",
    "    plt.tight_layout()\n",
    "    save_plot('cell_counts_group')\n",
    "    \n",
    "    print(f\"\\n✅ Group barplot saved as: cell_counts_group.png/.pdf\")\n",
    "    print(f\"Total cells visualized: {adata.shape[0]:,}\")\n",
    "    print(f\"Number of groups: {len(group_counts)}\")\n",
    "\n",
    "# === PLOT: LIBRARY COUNTS ===\n",
    "if 'library' in adata.obs.columns:\n",
    "    library_counts = adata.obs['library'].value_counts()\n",
    "    \n",
    "    print(f\"\\n--- Library cell counts ---\")\n",
    "    print(library_counts)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Create library barplot\n",
    "    ax2 = sns.countplot(data=adata.obs, x='library', color='#FF6B35',\n",
    "                       order=adata.obs['library'].cat.categories if hasattr(adata.obs['library'], 'cat') else None)\n",
    "    \n",
    "    plt.title('Cell Counts per Library', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Library', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Number of Cells', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "    plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    for p in ax2.patches:\n",
    "        count = int(p.get_height())\n",
    "        ax2.annotate(f'{count:,}', \n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                    ha='center', va='bottom', fontsize=10, fontweight='bold',\n",
    "                    color='black', xytext=(0, 8), textcoords='offset points')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax_save2 = sns.countplot(data=adata.obs, x='library', color='#FF6B35',\n",
    "                            order=adata.obs['library'].cat.categories if hasattr(adata.obs['library'], 'cat') else None)\n",
    "    plt.title('Cell Counts per Library', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Library', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Number of Cells', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "    plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    for p in ax_save2.patches:\n",
    "        count = int(p.get_height())\n",
    "        ax_save2.annotate(f'{count:,}', \n",
    "                        (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                        ha='center', va='bottom', fontsize=10, fontweight='bold',\n",
    "                        color='black', xytext=(0, 8), textcoords='offset points')\n",
    "    plt.tight_layout()\n",
    "    save_plot('cell_counts_library')\n",
    "    \n",
    "    print(f\"\\n✅ Library barplot saved as: cell_counts_library.png/.pdf\")\n",
    "    print(f\"Number of libraries: {len(library_counts)}\")\n",
    "\n",
    "# === PLOT: MOUSE COUNTS ===\n",
    "if 'mouse' in adata.obs.columns:\n",
    "    mouse_counts = adata.obs['mouse'].value_counts()\n",
    "    \n",
    "    print(f\"\\n--- Mouse cell counts ---\")\n",
    "    print(mouse_counts)\n",
    "    \n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    # Create mouse barplot\n",
    "    ax3 = sns.countplot(data=adata.obs, x='mouse', color='#4ECDC4',\n",
    "                       order=adata.obs['mouse'].cat.categories if hasattr(adata.obs['mouse'], 'cat') else None)\n",
    "    \n",
    "    plt.title('Cell Counts per Mouse', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Mouse', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Number of Cells', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "    plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    for p in ax3.patches:\n",
    "        count = int(p.get_height())\n",
    "        ax3.annotate(f'{count:,}', \n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                    ha='center', va='bottom', fontsize=9, fontweight='bold',\n",
    "                    color='black', xytext=(0, 8), textcoords='offset points')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    ax_save3 = sns.countplot(data=adata.obs, x='mouse', color='#4ECDC4',\n",
    "                            order=adata.obs['mouse'].cat.categories if hasattr(adata.obs['mouse'], 'cat') else None)\n",
    "    plt.title('Cell Counts per Mouse', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Mouse', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Number of Cells', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "    plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    for p in ax_save3.patches:\n",
    "        count = int(p.get_height())\n",
    "        ax_save3.annotate(f'{count:,}', \n",
    "                        (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                        ha='center', va='bottom', fontsize=9, fontweight='bold',\n",
    "                        color='black', xytext=(0, 8), textcoords='offset points')\n",
    "    plt.tight_layout()\n",
    "    save_plot('cell_counts_mouse')\n",
    "    \n",
    "    print(f\"\\n✅ Mouse barplot saved as: cell_counts_mouse.png/.pdf\")\n",
    "    print(f\"Number of mice: {len(mouse_counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b71fec7",
   "metadata": {},
   "source": [
    "## Quality Control (Optional)\n",
    "\n",
    "**Purpose**: This section can be used to visualize QC metrics by batch and filter out problematic samples if needed. You can skip to the next section if no additional filtering is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c144c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === QUALITY CONTROL WITH VISUALIZATIONS ===\n",
    "print(\"=== Quality Control Metrics ===\\n\")\n",
    "\n",
    "# Configure plot style\n",
    "configure_plot_style()\n",
    "\n",
    "# Determine which QC columns are available\n",
    "qc_columns = []\n",
    "for col in ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_ribo']:\n",
    "    if col in adata.obs.columns:\n",
    "        qc_columns.append(col)\n",
    "\n",
    "if len(qc_columns) == 0:\n",
    "    print(\"\\n⚠️  No standard QC columns found. Skipping QC plots.\")\n",
    "else:\n",
    "    print(f\"--- Generating QC Plots for: {qc_columns} ---\\n\")\n",
    "    \n",
    "    # Generate QC plots for each grouping variable\n",
    "    for groupby_var in ['group', 'batch', 'library', 'mouse']:\n",
    "        if groupby_var not in adata.obs.columns:\n",
    "            print(f\"⚠️  '{groupby_var}' column not found. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"--- Cell Counts by {groupby_var} ---\")\n",
    "        print(adata.obs[groupby_var].value_counts().sort_index())\n",
    "        print()\n",
    "        \n",
    "        # Create a figure with subplots for each QC metric\n",
    "        n_metrics = len(qc_columns)\n",
    "        figsize_width = 14 if groupby_var == 'mouse_ID' else 10\n",
    "        fig, axes = plt.subplots(n_metrics, 1, figsize=(figsize_width, 5 * n_metrics))\n",
    "        \n",
    "        # If only one metric, axes won't be an array\n",
    "        if n_metrics == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for idx, metric in enumerate(qc_columns):\n",
    "            # Create violin plot\n",
    "            sc.pl.violin(\n",
    "                adata, \n",
    "                keys=metric, \n",
    "                groupby=groupby_var,\n",
    "                rotation=90,\n",
    "                ax=axes[idx],\n",
    "                show=False\n",
    "            )\n",
    "            axes[idx].set_title(f'{metric} by {groupby_var}', fontsize=12, fontweight='bold')\n",
    "            axes[idx].set_xlabel(groupby_var, fontsize=10)\n",
    "            axes[idx].set_ylabel(metric, fontsize=10)\n",
    "            axes[idx].grid(axis='y', alpha=0.3, linestyle='--')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Save the plot\n",
    "        fig, axes = plt.subplots(n_metrics, 1, figsize=(figsize_width, 5 * n_metrics))\n",
    "        if n_metrics == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for idx, metric in enumerate(qc_columns):\n",
    "            sc.pl.violin(\n",
    "                adata, \n",
    "                keys=metric, \n",
    "                groupby=groupby_var,\n",
    "                rotation=90,\n",
    "                ax=axes[idx],\n",
    "                show=False\n",
    "            )\n",
    "            axes[idx].set_title(f'{metric} by {groupby_var}', fontsize=12, fontweight='bold')\n",
    "            axes[idx].set_xlabel(groupby_var, fontsize=10)\n",
    "            axes[idx].set_ylabel(metric, fontsize=10)\n",
    "            axes[idx].grid(axis='y', alpha=0.3, linestyle='--')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        save_plot(f\"qc_metrics_by_{groupby_var}\")\n",
    "        \n",
    "        print(f\"✅ QC plots saved as: qc_metrics_by_{groupby_var}.png/.pdf\\n\")\n",
    "\n",
    "# === CELL CYCLE DISTRIBUTION ===\n",
    "if 'phase' in adata.obs.columns:\n",
    "    print(\"--- Cell Cycle Distribution ---\")\n",
    "    \n",
    "    for groupby_var in ['group', 'batch', 'library', 'mouse']:\n",
    "        if groupby_var not in adata.obs.columns:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n{groupby_var.capitalize()} - Cell Cycle Phase Distribution:\")\n",
    "        \n",
    "        # Create crosstab\n",
    "        phase_counts = pd.crosstab(adata.obs[groupby_var], adata.obs['phase'], normalize='index') * 100\n",
    "        print(phase_counts.round(2))\n",
    "        \n",
    "        # Plot stacked bar chart\n",
    "        figsize_width = 14 if groupby_var == 'mouse_ID' else 10\n",
    "        fig, ax = plt.subplots(figsize=(figsize_width, 6))\n",
    "        phase_counts.plot(kind='bar', stacked=True, ax=ax, color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "        ax.set_title(f'Cell Cycle Phase Distribution by {groupby_var}', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel(groupby_var, fontsize=12)\n",
    "        ax.set_ylabel('Percentage of Cells', fontsize=12)\n",
    "        ax.legend(title='Phase', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.xticks(rotation=90, ha='right')\n",
    "        plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Save\n",
    "        fig, ax = plt.subplots(figsize=(figsize_width, 6))\n",
    "        phase_counts.plot(kind='bar', stacked=True, ax=ax, color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "        ax.set_title(f'Cell Cycle Phase Distribution by {groupby_var}', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel(groupby_var, fontsize=12)\n",
    "        ax.set_ylabel('Percentage of Cells', fontsize=12)\n",
    "        ax.legend(title='Phase', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.xticks(rotation=90, ha='right')\n",
    "        plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        save_plot(f\"cell_cycle_distribution_by_{groupby_var}\")\n",
    "        \n",
    "        print(f\"✅ Cell cycle plot saved as: cell_cycle_distribution_by_{groupby_var}.png/.pdf\")\n",
    "\n",
    "# === OPTIONAL FILTERING ===\n",
    "print(\"\\n--- Optional Filtering ---\")\n",
    "print(\"To remove problematic samples, uncomment and modify:\")\n",
    "print(\"# Remove by group: adata = adata[~adata.obs['group'].isin(['NI'])].copy()\")\n",
    "print(\"# Remove by batch: adata = adata[~adata.obs['batch'].isin(['batch1'])].copy()\")\n",
    "print(\"# Remove by library: adata = adata[~adata.obs['library'].isin(['APP-PS1-1'])].copy()\")\n",
    "print(\"# Remove by mouse: adata = adata[~adata.obs['mouse'].isin(['mouse1'])].copy()\")\n",
    "\n",
    "print(f\"\\n✅ Quality control complete\")\n",
    "print(f\"Dataset ready for modeling: {adata.shape[0]:,} cells, {adata.shape[1]:,} genes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f869539",
   "metadata": {},
   "source": [
    "## Data Preparation and scVI Setup\n",
    "\n",
    "**Purpose**: Prepare data for scVI modeling by creating separate datasets for training (HVG subset) and analysis (full genes), selecting highly variable genes, and configuring scVI with batch and covariate correction.\n",
    "\n",
    "**Key Steps**:\n",
    "- Create `adata_hvg`: HVG subset for efficient scVI training\n",
    "- Create `adata_full`: Full gene dataset for downstream analysis\n",
    "- Select 4,000 highly variable genes using Seurat v3 method\n",
    "- Store raw counts in `.layers['raw_counts']` for scVI modeling\n",
    "- Setup scVI with batch and covariate correction\n",
    "\n",
    "**scVI Configuration**:\n",
    "- **Batch key**: `batch` - corrects for batch effects across samples\n",
    "- **Categorical covariate**: `library` - accounts for library-specific effects\n",
    "- **Continuous covariates**: `S_score`, `G2M_score` - corrects for cell cycle effects\n",
    "\n",
    "This configuration allows scVI to model and correct for technical variation while preserving biological variation of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a5237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === BACKUP RAW COUNTS ===\n",
    "# Store raw RNA counts (with all genes) before HVG selection\n",
    "print(\"Preparing data for scVI modeling...\")\n",
    "raw_counts_full = adata.X.copy()\n",
    "\n",
    "# === CREATE SEPARATE COPIES FOR HVG AND FULL GENE DATASETS ===\n",
    "adata_hvg = adata.copy()  # This will be subsetted to HVGs for training\n",
    "adata_full = adata.copy()  # This preserves all genes for downstream analysis\n",
    "adata_full.layers['raw_counts'] = adata.X.copy()  # Store raw counts\n",
    "\n",
    "print(f\"✅ Created data copies:\")\n",
    "print(f\"  - adata_hvg: Will be subset to {N_TOP_GENES} HVGs for training\")\n",
    "print(f\"  - adata_full: Preserves all {adata_full.shape[1]:,} genes\")\n",
    "\n",
    "# === STORE ORIGINAL VAR NAMES ===\n",
    "original_var_names = adata_hvg.var_names.copy()\n",
    "\n",
    "# === HIGHLY VARIABLE GENE SELECTION ===\n",
    "print(f\"\\nSelecting {N_TOP_GENES} highly variable genes...\")\n",
    "sc.pp.highly_variable_genes(\n",
    "    adata_hvg,\n",
    "    n_top_genes=N_TOP_GENES,\n",
    "    flavor=\"seurat_v3\",\n",
    "    batch_key='library',  # Batch-specific HVG selection\n",
    "    subset=True\n",
    ")\n",
    "\n",
    "print(f\"✅ HVG selection complete: {adata_hvg.shape[1]} genes selected\")\n",
    "\n",
    "# === RESTORE RAW COUNTS FOR HVG-SELECTED GENES ===\n",
    "hvg_indices = [original_var_names.get_loc(gene) for gene in adata_hvg.var_names]\n",
    "adata_hvg.layers['raw_counts'] = raw_counts_full[:, hvg_indices]\n",
    "\n",
    "print(f\"✅ Raw counts layer created for HVG subset\")\n",
    "print(f\"  - Shape: {adata_hvg.layers['raw_counts'].shape}\")\n",
    "\n",
    "# === SCVI CONFIGURATION ===\n",
    "# **EDIT THESE VARIABLES TO CHANGE SCVI SETUP**\n",
    "BATCH_KEY = 'library'  # Column to use for batch correction\n",
    "CATEGORICAL_COVARIATES = []  # List of categorical covariates (e.g., ['sex'] or [])\n",
    "CONTINUOUS_COVARIATES = []  # List of continuous covariates (e.g., ['S_score', 'G2M_score'] or [])\n",
    "\n",
    "# === SETUP SCVI MODEL WITH BATCH AND COVARIATE CORRECTION ===\n",
    "print(f\"\\n--- Setting up scVI model ---\")\n",
    "print(f\"  - Batch correction: Enabled (batch_key='{BATCH_KEY}')\")\n",
    "print(f\"  - Number of batches: {adata_hvg.obs[BATCH_KEY].nunique()}\")\n",
    "print(f\"  - Batches: {sorted(adata_hvg.obs[BATCH_KEY].unique().tolist())}\")\n",
    "\n",
    "if CATEGORICAL_COVARIATES:\n",
    "    print(f\"  - Categorical covariates: {CATEGORICAL_COVARIATES}\")\n",
    "else:\n",
    "    print(f\"  - Categorical covariates: Not defined\")\n",
    "\n",
    "if CONTINUOUS_COVARIATES:\n",
    "    print(f\"  - Continuous covariates: {CONTINUOUS_COVARIATES}\")\n",
    "else:\n",
    "    print(f\"  - Continuous covariates: Not defined\")\n",
    "\n",
    "print(f\"  - Using raw counts from layer: 'raw_counts'\")\n",
    "\n",
    "# Build setup arguments dynamically\n",
    "setup_kwargs = {\n",
    "    'adata': adata_hvg,\n",
    "    'layer': 'raw_counts',\n",
    "    'batch_key': BATCH_KEY\n",
    "}\n",
    "\n",
    "if CATEGORICAL_COVARIATES:\n",
    "    setup_kwargs['categorical_covariate_keys'] = CATEGORICAL_COVARIATES\n",
    "\n",
    "if CONTINUOUS_COVARIATES:\n",
    "    setup_kwargs['continuous_covariate_keys'] = CONTINUOUS_COVARIATES\n",
    "\n",
    "# Setup scVI\n",
    "scvi.model.SCVI.setup_anndata(**setup_kwargs)\n",
    "\n",
    "# === DATA STRUCTURE CONFIRMATION ===\n",
    "print(\"\\n=== Data Structure Confirmation ===\")\n",
    "print(f\"✅ Data objects ready for scVI:\")\n",
    "print(f\"  - adata_hvg (for training): {adata_hvg.shape}\")\n",
    "print(f\"    • Genes: {adata_hvg.shape[1]:,} HVGs\")\n",
    "print(f\"    • Cells: {adata_hvg.shape[0]:,}\")\n",
    "print(f\"    • Raw counts layer: {adata_hvg.layers['raw_counts'].shape}\")\n",
    "print(f\"    • Batches: {adata_hvg.obs[BATCH_KEY].nunique()}\")\n",
    "print(f\"  - adata_full (for analysis): {adata_full.shape}\")\n",
    "print(f\"    • Genes: {adata_full.shape[1]:,} (all genes)\")\n",
    "print(f\"    • Cells: {adata_full.shape[0]:,}\")\n",
    "print(f\"    • Raw counts layer: {adata_full.layers['raw_counts'].shape}\")\n",
    "\n",
    "print(f\"\\n✅ Metadata preservation:\")\n",
    "print(f\"  - Cells: {adata_hvg.shape[0]:,}\")\n",
    "print(f\"  - Metadata columns: {adata_hvg.obs.shape[1]}\")\n",
    "print(f\"  - Key columns: batch, library, group, mouse\")\n",
    "\n",
    "print(f\"\\n✅ scVI setup complete - ready for training!\")\n",
    "print(f\"Note: Batch correction applied for '{BATCH_KEY}' ({adata_hvg.obs[BATCH_KEY].nunique()} batches).\")\n",
    "if CATEGORICAL_COVARIATES:\n",
    "    print(f\"      Categorical covariates: {', '.join(CATEGORICAL_COVARIATES)}\")\n",
    "else:\n",
    "    print(f\"      Categorical covariates: Not defined\")\n",
    "if CONTINUOUS_COVARIATES:\n",
    "    print(f\"      Continuous covariates: {', '.join(CONTINUOUS_COVARIATES)}\")\n",
    "else:\n",
    "    print(f\"      Continuous covariates: Not defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60c0eab",
   "metadata": {},
   "source": [
    "## scVI Model Training\n",
    "\n",
    "**Purpose**: Train scVI model for covariate correction and generate latent representations for downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eee0c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DEVICE CONFIGURATION ===\n",
    "# Automatically detect and configure training device\n",
    "if torch.backends.mps.is_available():\n",
    "    accelerator = \"mps\"\n",
    "    devices = 1\n",
    "    print(\"MPS (Apple Silicon GPU) available. Using MPS for training.\")\n",
    "elif torch.cuda.is_available():\n",
    "    accelerator = \"gpu\"\n",
    "    devices = 1\n",
    "    print(\"CUDA GPU available. Using GPU for training.\")\n",
    "else:\n",
    "    accelerator = \"cpu\"\n",
    "    devices = \"auto\"\n",
    "    print(\"No GPU available. Using CPU for training.\")\n",
    "\n",
    "# === MODEL INITIALIZATION ===\n",
    "print(f\"\\nInitializing scVI model...\")\n",
    "model = scvi.model.SCVI(adata_hvg, n_latent=20, n_layers=2)\n",
    "\n",
    "# === TRAINING CONFIGURATION ===\n",
    "print(f\"Training configuration:\")\n",
    "print(f\"  - Max epochs: {MAX_EPOCHS}\")\n",
    "print(f\"  - Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  - Accelerator: {accelerator}\")\n",
    "print(f\"  - Early stopping patience: {EARLY_STOPPING_PATIENCE}\")\n",
    "print(f\"  - Training on: {adata_hvg.shape[0]:,} cells, {adata_hvg.shape[1]:,} HVGs\")\n",
    "\n",
    "# === MODEL TRAINING ===\n",
    "print(\"\\nStarting scVI training...\")\n",
    "model.train(\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    accelerator=accelerator,\n",
    "    devices=devices,\n",
    "    early_stopping=True,\n",
    "    early_stopping_patience=EARLY_STOPPING_PATIENCE\n",
    ")\n",
    "\n",
    "# === TRAINING VISUALIZATION ===\n",
    "configure_plot_style()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(model.history['elbo_train']['elbo_train'], label='Training ELBO', alpha=0.8)\n",
    "plt.plot(model.history['elbo_validation']['elbo_validation'], label='Validation ELBO', alpha=0.8)\n",
    "plt.xlabel(\"Epoch\", fontsize=12)\n",
    "plt.ylabel(\"ELBO Loss\", fontsize=12)\n",
    "plt.title(\"scVI Training Progress\", fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "show_inline_plot()\n",
    "save_plot(\"scvi_training_elbo_loss\")\n",
    "\n",
    "# === EXTRACT LATENT REPRESENTATIONS ===\n",
    "latent_key = \"X_scVI\"\n",
    "print(f\"\\nExtracting latent representations...\")\n",
    "\n",
    "# Get latent representation\n",
    "latent_representation = model.get_latent_representation()\n",
    "\n",
    "# Store in both HVG and full gene objects\n",
    "adata_hvg.obsm[latent_key] = latent_representation\n",
    "adata_full.obsm[latent_key] = latent_representation\n",
    "\n",
    "print(f\"Latent representation stored in:\")\n",
    "print(f\"  - adata_hvg.obsm['{latent_key}']: {latent_representation.shape}\")\n",
    "print(f\"  - adata_full.obsm['{latent_key}']: {latent_representation.shape}\")\n",
    "\n",
    "# === TRAINING SUMMARY ===\n",
    "print(\"\\n=== Training Complete ===\")\n",
    "\n",
    "# Safely access training history\n",
    "if len(model.history['elbo_train']['elbo_train']) > 0:\n",
    "    print(f\"Final training ELBO: {model.history['elbo_train']['elbo_train'].iloc[-1]:.2f}\")\n",
    "    print(f\"Final validation ELBO: {model.history['elbo_validation']['elbo_validation'].iloc[-1]:.2f}\")\n",
    "else:\n",
    "    print(\"Training history not available (possible early convergence)\")\n",
    "    \n",
    "print(f\"Latent dimensions: {latent_representation.shape[1]}\")\n",
    "print(f\"Total cells: {latent_representation.shape[0]:,}\")\n",
    "print(f\"Batch correction applied for: '{BATCH_KEY}' ({adata_hvg.obs[BATCH_KEY].nunique()} batches)\")\n",
    "if CATEGORICAL_COVARIATES:\n",
    "    print(f\"Categorical covariates: {', '.join(CATEGORICAL_COVARIATES)}\")\n",
    "if CONTINUOUS_COVARIATES:\n",
    "    print(f\"Continuous covariates: {', '.join(CONTINUOUS_COVARIATES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ff015e",
   "metadata": {},
   "source": [
    "## Post-Training Verification\n",
    "\n",
    "**Purpose**: Verify that the scVI training was successful, latent representations are properly stored, and all metadata columns are preserved for downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb75cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === VERIFY DATA TRANSFER ===\n",
    "print(\"\\n=== Verifying Latent Space Transfer ===\")\n",
    "print(f\"✅ Latent representation successfully stored:\")\n",
    "print(f\"  - adata_hvg.obsm['X_scVI']: {adata_hvg.obsm['X_scVI'].shape}\")\n",
    "print(f\"  - adata_full.obsm['X_scVI']: {adata_full.obsm['X_scVI'].shape}\")\n",
    "\n",
    "# === VERIFY METADATA AVAILABILITY ===\n",
    "print(\"\\n=== Metadata Verification ===\")\n",
    "# Check for columns that exist in your data\n",
    "important_columns = ['batch', 'library', 'group', 'mouse', 'phase']\n",
    "if 'S_score' in adata_full.obs.columns:\n",
    "    important_columns.extend(['S_score', 'G2M_score', 'pct_counts_mt'])\n",
    "\n",
    "for col in important_columns:\n",
    "    if col in adata_full.obs.columns:\n",
    "        unique_count = adata_full.obs[col].nunique()\n",
    "        print(f\"✅ {col}: {unique_count} unique values\")\n",
    "    else:\n",
    "        print(f\"❌ {col}: Not found\")\n",
    "\n",
    "# === SUMMARY ===\n",
    "print(\"\\n=== Ready for Downstream Analysis ===\")\n",
    "print(f\"✅ scVI training complete\")\n",
    "print(f\"✅ Latent space available in both adata_hvg and adata_full\")\n",
    "print(f\"✅ Use adata_full for downstream analysis (has all {adata_full.shape[1]:,} genes)\")\n",
    "print(f\"✅ Batch correction applied for '{BATCH_KEY}' ({adata_full.obs[BATCH_KEY].nunique()} batches)\")\n",
    "if CATEGORICAL_COVARIATES:\n",
    "    print(f\"✅ Categorical covariates: {', '.join(CATEGORICAL_COVARIATES)}\")\n",
    "if CONTINUOUS_COVARIATES:\n",
    "    print(f\"✅ Continuous covariates: {', '.join(CONTINUOUS_COVARIATES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c633a496",
   "metadata": {},
   "source": [
    "### Data Object Summary\n",
    "\n",
    "**Purpose**: Verify data structure and confirm both adata objects are ready for downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb9f918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DATA OBJECT SUMMARY ===\n",
    "print(\"=== Data Object Summary ===\\n\")\n",
    "\n",
    "print(\"--- adata_hvg (for training) ---\")\n",
    "print(f\"  Cells: {adata_hvg.shape[0]:,} | Genes: {adata_hvg.shape[1]:,} HVGs\")\n",
    "print(f\"  Latent space: {'X_scVI' in adata_hvg.obsm}\")\n",
    "\n",
    "print(\"\\n--- adata_full (for analysis) ---\")\n",
    "print(f\"  Cells: {adata_full.shape[0]:,} | Genes: {adata_full.shape[1]:,} (all genes)\")\n",
    "print(f\"  Latent space: {adata_full.obsm['X_scVI'].shape if 'X_scVI' in adata_full.obsm else 'Not found'}\")\n",
    "print(f\"  Raw counts: {adata_full.layers['raw_counts'].shape}\")\n",
    "\n",
    "print(\"\\n--- Recommendation ---\")\n",
    "print(\"✅ Use adata_full for all downstream analysis (clustering, UMAP, DE, visualization)\")\n",
    "\n",
    "print(\"\\n✅ Data verification complete - ready for downstream analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6bb387",
   "metadata": {},
   "source": [
    "## Save Integrated Data\n",
    "\n",
    "**Purpose**: Save the integrated MuData objects (HVG subset and full genes) for downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b26bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SAVE INTEGRATED DATA ===\n",
    "print(\"Saving integrated AnnData object...\")\n",
    "\n",
    "# Remove problematic column before saving\n",
    "if 'most_likely_hypothesis' in adata_full.obs.columns:\n",
    "    print(\"Removing 'most_likely_hypothesis' column (not compatible with h5ad format)\")\n",
    "    adata_full.obs.drop(columns=['most_likely_hypothesis'], inplace=True)\n",
    "\n",
    "# Save full genes only\n",
    "output_filename = \"integrated_library\"\n",
    "adata_full.write_h5ad(output_dir / f\"{output_filename}.h5ad\", compression=\"gzip\")\n",
    "\n",
    "# File info\n",
    "file_size = (output_dir / f\"{output_filename}.h5ad\").stat().st_size / (1024**2)\n",
    "print(f\"\\n✅ Saved: {output_filename}.h5ad ({file_size:.1f} MB)\")\n",
    "print(f\"   - {adata_full.shape[0]:,} cells, {adata_full.shape[1]:,} genes\")\n",
    "print(f\"   - Latent dims: {adata_full.obsm['X_scVI'].shape[1]}\")\n",
    "print(f\"   - Batch key: '{BATCH_KEY}' ({adata_full.obs[BATCH_KEY].nunique()} batches)\")\n",
    "if CATEGORICAL_COVARIATES:\n",
    "    print(f\"   - Categorical: {', '.join(CATEGORICAL_COVARIATES)}\")\n",
    "if CONTINUOUS_COVARIATES:\n",
    "    print(f\"   - Continuous: {', '.join(CONTINUOUS_COVARIATES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb79a90",
   "metadata": {},
   "source": [
    "## Analysis Summary\n",
    "\n",
    "**Purpose**: Document analysis completion, environment details, and output files for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170d225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ANALYSIS COMPLETION SUMMARY ===\n",
    "print(\"=== SINGLE-CELL Integration ANALYSIS COMPLETE ===\\n\")\n",
    "\n",
    "# === ENVIRONMENT INFORMATION ===\n",
    "print(\"--- Environment Details ---\")\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "print(f\"Analysis completed: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# === PACKAGE VERSIONS ===\n",
    "print(\"\\n--- Package Versions ---\")\n",
    "packages = ['anndata', 'scanpy', 'scvi-tools', 'mudata', 'muon', 'torch']\n",
    "for pkg in packages:\n",
    "    try:\n",
    "        version = pkg_resources.get_distribution(pkg).version\n",
    "        print(f\"{pkg}: {version}\")\n",
    "    except:\n",
    "        print(f\"{pkg}: Not available\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c0c09e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scRNAseq-scVI Env",
   "language": "python",
   "name": "scrnaseq-scvi_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
